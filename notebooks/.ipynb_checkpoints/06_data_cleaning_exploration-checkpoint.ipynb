{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4a25a6d-a0a5-4ee8-91cd-bfcf074b7ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Environment loaded successfully\n",
      "üìä Supabase URL: https://lgnhjzlbezpczlobeevu.s...\n",
      "üîë API Key loaded: 208 characters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import html\n",
    "import unicodedata\n",
    "from dotenv import load_dotenv\n",
    "from supabase import create_client, Client\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# Initialize Supabase client\n",
    "SUPABASE_URL = \"https://lgnhjzlbezpczlobeevu.supabase.co\"\n",
    "SUPABASE_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImxnbmhqemxiZXpwY3psb2JlZXZ1Iiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTgyMDgzNjcsImV4cCI6MjA3Mzc4NDM2N30.O5Yt0dOyYq326ESo0LBL7lGj4k8zwpuodJfTtGwrPek\"\n",
    "\n",
    "\n",
    "if not SUPABASE_URL or not SUPABASE_KEY:\n",
    "    raise ValueError(\"Missing Supabase credentials in .env file\")\n",
    "\n",
    "supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)\n",
    "\n",
    "print(\"‚úÖ Environment loaded successfully\")\n",
    "print(f\"üìä Supabase URL: {SUPABASE_URL[:30]}...\")\n",
    "print(f\"üîë API Key loaded: {len(SUPABASE_KEY)} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af65d23f-29d5-4950-8f7d-589c76670df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully connected to Supabase\n",
      "üìà Total rows in news_raw: 745\n",
      "\n",
      "üìä Data Breakdown:\n",
      "   - RSS articles: 100\n",
      "   - Archive articles: 645\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Get total count\n",
    "    response = supabase.table('news_cleaned').select('id', count='exact').execute()\n",
    "    \n",
    "    print(f\"‚úÖ Successfully connected to Supabase\")\n",
    "    print(f\"üìà Total rows in news_cleaned: {total_count}\")\n",
    "    \n",
    "    # Get breakdown by source\n",
    "    rss_response = supabase.table('news_cleaned').select('id', count='exact').eq('source', 'The Hindu - RSS').execute()\n",
    "    archive_response = supabase.table('news_cleaned').select('id', count='exact').eq('source', 'The Hindu - Archive').execute()\n",
    "    \n",
    "    print(f\"\\nüìä Data Breakdown:\")\n",
    "    print(f\"   - RSS articles: {rss_response.count}\")\n",
    "    print(f\"   - Archive articles: {archive_response.count}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error connecting to Supabase: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ca309e5-20e3-4627-aee0-e898082a33de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Retrieved 10 rows for testing\n",
      "   - RSS: 5 rows\n",
      "   - Archive: 5 rows\n",
      "\n",
      "üìã Sample DataFrame shape: (10, 9)\n",
      "\n",
      "üîç Columns: ['id', 'title', 'description', 'content_full', 'category', 'source', 'link', 'pub_date', 'archive_date']\n"
     ]
    }
   ],
   "source": [
    "# Fetch 5 RSS articles\n",
    "rss_sample = supabase.table('news_cleaned')\\\n",
    "    .select('id, title, description, content_full, category, source, link, pub_date, archive_date')\\\n",
    "    .eq('source', 'The Hindu - RSS')\\\n",
    "    .limit(5)\\\n",
    "    .execute()\n",
    "\n",
    "# Fetch 5 Archive articles\n",
    "archive_sample = supabase.table('news_cleaned')\\\n",
    "    .select('id, title, description, content_full, category, source, link, pub_date, archive_date')\\\n",
    "    .eq('source', 'The Hindu - Archive')\\\n",
    "    .limit(5)\\\n",
    "    .execute()\n",
    "\n",
    "# Combine into DataFrame\n",
    "rss_df = pd.DataFrame(rss_sample.data)\n",
    "archive_df = pd.DataFrame(archive_sample.data)\n",
    "sample_df = pd.concat([rss_df, archive_df], ignore_index=True)\n",
    "\n",
    "print(f\"‚úÖ Retrieved {len(sample_df)} rows for testing\")\n",
    "print(f\"   - RSS: {len(rss_df)} rows\")\n",
    "print(f\"   - Archive: {len(archive_df)} rows\")\n",
    "print(f\"\\nüìã Sample DataFrame shape: {sample_df.shape}\")\n",
    "print(f\"\\nüîç Columns: {list(sample_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03c8e3f7-5913-440f-a0f7-f18fd6afff0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "RAW DATA SAMPLE - MANUAL VERIFICATION\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "ROW 1 | ID: 41eb8377-f89f-499a-8f3a-212e537b42de | SOURCE: The Hindu - RSS\n",
      "================================================================================\n",
      "\n",
      "üìå TITLE:\n",
      "Orange alert issued in north Tamil Nadu districts as Cyclone Montha advances\n",
      "\n",
      "üìÅ CATEGORY:\n",
      "Tamil Nadu\n",
      "\n",
      "üìù DESCRIPTION:\n",
      "In its Nowcast till 1 p.m. on Monday (October 27), the RMC has predicted moderate rains to continue over Chennai and its neighbouring districts, and Villupuram and Ranipet\n",
      "\n",
      "üìÑ CONTENT_FULL:\n",
      "‚ùå EMPTY/NULL\n",
      "\n",
      "üîó LINK: https://www.thehindu.com/news/national/tamil-nadu/cyclone-montha-orange-alert-issued-in-north-tamil-nadu-districts-as-weather-system-advances/article70207325.ece\n",
      "üìÖ PUB_DATE: 2025-10-27T12:23:45+00:00\n",
      "üìÖ ARCHIVE_DATE: None\n",
      "\n",
      "================================================================================\n",
      "ROW 2 | ID: 6067d8d8-dff9-47c8-8121-b6ea7fa6f619 | SOURCE: The Hindu - RSS\n",
      "================================================================================\n",
      "\n",
      "üìå TITLE:\n",
      "Kalaignar International Convention Centre set for completion by February 2026: Minister E.V. Velu\n",
      "\n",
      "üìÅ CATEGORY:\n",
      "Chennai\n",
      "\n",
      "üìù DESCRIPTION:\n",
      "The Public Works Department started the ‚Çπ525-crore project in May this year\n",
      "\n",
      "üìÑ CONTENT_FULL:\n",
      "‚ùå EMPTY/NULL\n",
      "\n",
      "üîó LINK: https://www.thehindu.com/news/cities/chennai/kalaignar-international-convention-centre-set-for-completion-by-february-2026-minister-ev-velu/article70207237.ece\n",
      "üìÖ PUB_DATE: 2025-10-27T11:59:34+00:00\n",
      "üìÖ ARCHIVE_DATE: None\n",
      "\n",
      "================================================================================\n",
      "ROW 3 | ID: 7c9518c5-2224-4cd6-afc5-4318c78237c7 | SOURCE: The Hindu - RSS\n",
      "================================================================================\n",
      "\n",
      "üìå TITLE:\n",
      "Eminent plastic surgeon K. Mathangi Ramakrishnan no more\n",
      "\n",
      "üìÅ CATEGORY:\n",
      "Tamil Nadu\n",
      "\n",
      "üìù DESCRIPTION:\n",
      "She established the plastic surgery department and burns unit at Government Kilpauk Medical College, Chennai ‚Äî one of the foremost government centres in India dedicated to comprehensive burn care and rehabilitation\n",
      "\n",
      "üìÑ CONTENT_FULL:\n",
      "‚ùå EMPTY/NULL\n",
      "\n",
      "üîó LINK: https://www.thehindu.com/news/national/tamil-nadu/eminent-plastic-surgeon-k-mathangi-ramakrishnan-no-more/article70207162.ece\n",
      "üìÖ PUB_DATE: 2025-10-27T11:09:02+00:00\n",
      "üìÖ ARCHIVE_DATE: None\n",
      "\n",
      "================================================================================\n",
      "ROW 4 | ID: a29498b2-9a64-4e13-b78b-7edd00272200 | SOURCE: The Hindu - RSS\n",
      "================================================================================\n",
      "\n",
      "üìå TITLE:\n",
      "What is the problem faced by paddy farmers of Tamil Nadu? | Explained\n",
      "\n",
      "üìÅ CATEGORY:\n",
      "Tamil Nadu\n",
      "\n",
      "üìù DESCRIPTION:\n",
      "Why are there issues with procuring and storing paddy from the Cauvery delta?\n",
      "\n",
      "üìÑ CONTENT_FULL:\n",
      "‚ùå EMPTY/NULL\n",
      "\n",
      "üîó LINK: https://www.thehindu.com/news/national/tamil-nadu/what-is-the-problem-faced-by-paddy-farmers-of-tamil-nadu-explained/article70206033.ece\n",
      "üìÖ PUB_DATE: 2025-10-27T08:30:00+00:00\n",
      "üìÖ ARCHIVE_DATE: None\n",
      "\n",
      "================================================================================\n",
      "ROW 5 | ID: c468b884-94b3-4973-9f05-6601255010c7 | SOURCE: The Hindu - RSS\n",
      "================================================================================\n",
      "\n",
      "üìå TITLE:\n",
      "BM reviews works in Adyar estuary\n",
      "\n",
      "üìÅ CATEGORY:\n",
      "Tamil Nadu\n",
      "\n",
      "üìù DESCRIPTION:\n",
      "Besides the widening and desilting of Adyar estuary, the CM instructed officials to undertake the widening and desilting works in Cooum, Muttukadu and Ennore estuaries\n",
      "\n",
      "üìÑ CONTENT_FULL:\n",
      "‚ùå EMPTY/NULL\n",
      "\n",
      "üîó LINK: https://www.thehindu.com/news/national/tamil-nadu/briefly-cm-reviews-works-in-adyar-estuary/article70204360.ece\n",
      "üìÖ PUB_DATE: 2025-10-27T07:35:37+00:00\n",
      "üìÖ ARCHIVE_DATE: None\n",
      "\n",
      "================================================================================\n",
      "ROW 6 | ID: 9b5243c4-5ef7-4847-9efb-277da6f2ba33 | SOURCE: The Hindu - Archive\n",
      "================================================================================\n",
      "\n",
      "üìå TITLE:\n",
      "Wild elephants damage 30 coconut trees near Coimbatore\n",
      "\n",
      "üìÅ CATEGORY:\n",
      "Coimbatore\n",
      "\n",
      "üìù DESCRIPTION:\n",
      "‚ùå EMPTY/NULL\n",
      "\n",
      "üìÑ CONTENT_FULL:\n",
      "Wild elephants damaged 30 coconut trees at a farm in Dhaliyur near Thondamuthur in Coimbatore district on Monday night.\n",
      "The elephants entered the nine-acre farm, belonging to N. Suganya and Senthil Nathan, from an adjacent farm after crop raiding. The elephants damaged a solar fencing to enter the coconut farm, where they damaged 30 trees aged between two and four years.\n",
      "According to Ms. Suganya, the farm is located around 500 metres from the forest boundary. Elephants damaged four coconut trees...\n",
      "[Total length: 990 characters]\n",
      "\n",
      "üîó LINK: https://www.thehindu.com/news/cities/Coimbatore/elephants-damage-30-coconut-trees-near-coimbatore/article70113643.ece\n",
      "üìÖ PUB_DATE: None\n",
      "üìÖ ARCHIVE_DATE: 2025-10-01\n",
      "\n",
      "================================================================================\n",
      "ROW 7 | ID: 5af5e88a-b15f-4e5e-a15e-ce61a777abeb | SOURCE: The Hindu - Archive\n",
      "================================================================================\n",
      "\n",
      "üìå TITLE:\n",
      "Welfare assistance distributed to over 1,500 beneficiaries in Salem district\n",
      "\n",
      "üìÅ CATEGORY:\n",
      "Coimbatore\n",
      "\n",
      "üìù DESCRIPTION:\n",
      "‚ùå EMPTY/NULL\n",
      "\n",
      "üìÑ CONTENT_FULL:\n",
      "Minister for Public Works, E. V. Velu, and Minister for Tourism, R. Rajendran, distributed welfare assistance worth ‚Çπ10.66 crore to 1,572 beneficiaries, including women, self-help groups (SHGs), differently-abled persons and widows, here on Tuesday (September 30, 2025).\n",
      "At a function organised by the Salem District Central Cooperative Bank, Mr. Velu said that former Chief Minister M. Karunanidhi had introduced landmark welfare schemes, including waiver of cooperative jewellery loans worth ‚Çπ7,000...\n",
      "[Total length: 1993 characters]\n",
      "\n",
      "üîó LINK: https://www.thehindu.com/news/cities/Coimbatore/welfare-assistance-distributed-to-over-1500-beneficiaries-in-salem-district/article70112322.ece\n",
      "üìÖ PUB_DATE: None\n",
      "üìÖ ARCHIVE_DATE: 2025-10-01\n",
      "\n",
      "================================================================================\n",
      "ROW 8 | ID: 2176067d-6e1c-42d8-a71e-4813e5e76331 | SOURCE: The Hindu - Archive\n",
      "================================================================================\n",
      "\n",
      "üìå TITLE:\n",
      "Garland from Srivilliputtur Andal Temple taken to Tirumala\n",
      "\n",
      "üìÅ CATEGORY:\n",
      "Madurai\n",
      "\n",
      "üìù DESCRIPTION:\n",
      "‚ùå EMPTY/NULL\n",
      "\n",
      "üìÑ CONTENT_FULL:\n",
      "S\n",
      "After performing special pujas, priests from the Andal Temple here carried garland and vasthram, among other offerings, to the presiding deity in Tirumala on Sunday, where the annual brahmotsavam is being held as part of Purattasi month.\n",
      "The rituals commenced with special pujas to the deity here in the presence of HR&CE officials and members of the Board of Trustees on Friday. Devotees chanting ‚ÄòGovinda, Govinda‚Äô went around the temple when the garland was being carried in a procession by seni...\n",
      "[Total length: 665 characters]\n",
      "\n",
      "üîó LINK: https://www.thehindu.com/news/cities/Madurai/garland-from-srivilliputtur-andal-temple-taken-to-tirumala/article70102659.ece\n",
      "üìÖ PUB_DATE: None\n",
      "üìÖ ARCHIVE_DATE: 2025-09-28\n",
      "\n",
      "================================================================================\n",
      "ROW 9 | ID: 3701bf78-4227-4f6d-bd8b-2dfa1bc2f06f | SOURCE: The Hindu - Archive\n",
      "================================================================================\n",
      "\n",
      "üìå TITLE:\n",
      "85 establishments booked for working on Gandhi Jayanthi in Erode\n",
      "\n",
      "üìÅ CATEGORY:\n",
      "Coimbatore\n",
      "\n",
      "üìù DESCRIPTION:\n",
      "‚ùå EMPTY/NULL\n",
      "\n",
      "üìÑ CONTENT_FULL:\n",
      "The Labour Department has registered cases against 85 shops, eateries, commercial establishments, and transport companies for not declaring a holiday for employees on October 2 (Thursday), Gandhi Jayanthi and for not paying them double wages.\n",
      "In a release, K. Jeyalakshmi, Assistant Commissioner of Labour (Enforcement), said officials inspected 106 establishments in Erode, Bhavani, Perundurai, Gobichettipalayam, and Sathyamangalam on Thursday. Of these, 85 neither declared a holiday for employees...\n",
      "[Total length: 825 characters]\n",
      "\n",
      "üîó LINK: https://www.thehindu.com/news/cities/Coimbatore/85-establishments-booked-for-working-on-gandhi-jayanthi-in-erode/article70117512.ece\n",
      "üìÖ PUB_DATE: None\n",
      "üìÖ ARCHIVE_DATE: 2025-10-03\n",
      "\n",
      "================================================================================\n",
      "ROW 10 | ID: 2f4a683d-31a7-4d8e-8961-fa97490a83d3 | SOURCE: The Hindu - Archive\n",
      "================================================================================\n",
      "\n",
      "üìå TITLE:\n",
      "PenmAI draws huge turnout of women from southern districts held at TSM\n",
      "\n",
      "üìÅ CATEGORY:\n",
      "Madurai\n",
      "\n",
      "üìù DESCRIPTION:\n",
      "‚ùå EMPTY/NULL\n",
      "\n",
      "üìÑ CONTENT_FULL:\n",
      "PenmAI 2025, a first of its kind AI (artificial intelligence) upskilling workshop was organised at the Thiagarajar School of Management.\n",
      "A day-long workshop dedicated exclusively to empowering women through AI drew a huge turnout from many southern districts.\n",
      "The Incubation Center of TSM, in collaboration with Google, StartupTN and Google Developers aimed to upskill 2,025 women in the year 2025, symbolising inclusivity and innovation.\n",
      "Surpassing expectations, over 2,500 women participants from a...\n",
      "[Total length: 1512 characters]\n",
      "\n",
      "üîó LINK: https://www.thehindu.com/news/cities/Madurai/penmai-draws-huge-turnout-of-women-from-southern-districts-held-at-tsm/article70113802.ece\n",
      "üìÖ PUB_DATE: None\n",
      "üìÖ ARCHIVE_DATE: 2025-10-01\n",
      "\n",
      "================================================================================\n",
      "END OF RAW DATA SAMPLE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)  # No truncation\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"RAW DATA SAMPLE - MANUAL VERIFICATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for idx, row in sample_df.iterrows():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ROW {idx + 1} | ID: {row['id']} | SOURCE: {row['source']}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    print(f\"\\nüìå TITLE:\")\n",
    "    print(f\"{row['title']}\")\n",
    "    \n",
    "    print(f\"\\nüìÅ CATEGORY:\")\n",
    "    print(f\"{row['category']}\")\n",
    "    \n",
    "    print(f\"\\nüìù DESCRIPTION:\")\n",
    "    if pd.notna(row['description']) and row['description']:\n",
    "        print(f\"{row['description']}\")\n",
    "    else:\n",
    "        print(\"‚ùå EMPTY/NULL\")\n",
    "    \n",
    "    print(f\"\\nüìÑ CONTENT_FULL:\")\n",
    "    if pd.notna(row['content_full']) and row['content_full']:\n",
    "        print(f\"{row['content_full'][:500]}...\")  # Show first 500 chars\n",
    "        print(f\"[Total length: {len(row['content_full'])} characters]\")\n",
    "    else:\n",
    "        print(\"‚ùå EMPTY/NULL\")\n",
    "    \n",
    "    print(f\"\\nüîó LINK: {row['link']}\")\n",
    "    print(f\"üìÖ PUB_DATE: {row['pub_date']}\")\n",
    "    print(f\"üìÖ ARCHIVE_DATE: {row['archive_date']}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"END OF RAW DATA SAMPLE\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "156d6caa-7d29-4a0c-9ab9-dbcf452ee263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DATA QUALITY ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "üìä Content Availability:\n",
      "   - Rows with description: 5 / 10\n",
      "   - Rows with content_full: 5 / 10\n",
      "   - Rows with BOTH: 0 / 10\n",
      "   - Rows with NEITHER: 0 / 10\n",
      "\n",
      "üìÇ Category Distribution:\n",
      "category\n",
      "Tamil Nadu    4\n",
      "Coimbatore    3\n",
      "Madurai       2\n",
      "Chennai       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üìè Text Length Statistics:\n",
      "   Title: min=33, max=97, avg=65.3\n",
      "   Description: min=0, max=214, avg=70.4\n",
      "   Content: min=0, max=1993, avg=598.5\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"DATA QUALITY ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Check for missing content\n",
    "has_description = sample_df['description'].notna() & (sample_df['description'] != '')\n",
    "has_content_full = sample_df['content_full'].notna() & (sample_df['content_full'] != '')\n",
    "\n",
    "print(f\"\\nüìä Content Availability:\")\n",
    "print(f\"   - Rows with description: {has_description.sum()} / {len(sample_df)}\")\n",
    "print(f\"   - Rows with content_full: {has_content_full.sum()} / {len(sample_df)}\")\n",
    "print(f\"   - Rows with BOTH: {(has_description & has_content_full).sum()} / {len(sample_df)}\")\n",
    "print(f\"   - Rows with NEITHER: {(~has_description & ~has_content_full).sum()} / {len(sample_df)}\")\n",
    "\n",
    "# Flag rows with missing content\n",
    "missing_both = sample_df[~has_description & ~has_content_full]\n",
    "if len(missing_both) > 0:\n",
    "    print(f\"\\n‚ö†Ô∏è  FLAGGED: {len(missing_both)} rows with NO content\")\n",
    "    print(\"   IDs:\", missing_both['id'].tolist())\n",
    "\n",
    "# Category distribution\n",
    "print(f\"\\nüìÇ Category Distribution:\")\n",
    "print(sample_df['category'].value_counts())\n",
    "\n",
    "# Character length analysis\n",
    "sample_df['title_length'] = sample_df['title'].fillna('').str.len()\n",
    "sample_df['desc_length'] = sample_df['description'].fillna('').str.len()\n",
    "sample_df['content_length'] = sample_df['content_full'].fillna('').str.len()\n",
    "\n",
    "print(f\"\\nüìè Text Length Statistics:\")\n",
    "print(f\"   Title: min={sample_df['title_length'].min()}, max={sample_df['title_length'].max()}, avg={sample_df['title_length'].mean():.1f}\")\n",
    "print(f\"   Description: min={sample_df['desc_length'].min()}, max={sample_df['desc_length'].max()}, avg={sample_df['desc_length'].mean():.1f}\")\n",
    "print(f\"   Content: min={sample_df['content_length'].min()}, max={sample_df['content_length'].max()}, avg={sample_df['content_length'].mean():.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e8b8038-9aad-49e3-ba62-dc835b038e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cleaning functions defined:\n",
      "   - clean_text(text)\n",
      "   - clean_title(title)\n",
      "   - clean_description(description)\n",
      "   - clean_content(content)\n",
      "   - standardize_category(category)\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Define text cleaning functions\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    General purpose text cleaner\n",
    "    Handles: None values, whitespace normalization, encoding fixes\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or text is None or text == '':\n",
    "        return None\n",
    "    \n",
    "    # Convert to string\n",
    "    text = str(text)\n",
    "    \n",
    "    # Decode HTML entities (e.g., &amp; -> &, &quot; -> \")\n",
    "    text = html.unescape(text)\n",
    "    \n",
    "    # Fix common encoding issues\n",
    "    encoding_fixes = {\n",
    "        '√¢‚Ç¨‚Ñ¢': \"'\",  # Smart apostrophe\n",
    "        '√¢‚Ç¨≈ì': '\"',  # Smart quote open\n",
    "        '√¢‚Ç¨': '\"',   # Smart quote close\n",
    "        '√¢‚Ç¨\"': '‚Äî',  # Em dash\n",
    "        '√¢‚Ç¨\"': '‚Äì',  # En dash\n",
    "        '√É¬°': '√°',\n",
    "        '√É¬©': '√©',\n",
    "        '√É¬≠': '√≠',\n",
    "        '√É¬≥': '√≥',\n",
    "        '√É¬∫': '√∫',\n",
    "        '√¢‚Äö¬π': '‚Çπ',  # Rupee symbol\n",
    "    }\n",
    "    \n",
    "    for wrong, right in encoding_fixes.items():\n",
    "        text = text.replace(wrong, right)\n",
    "    \n",
    "    # Normalize Unicode characters\n",
    "    text = unicodedata.normalize('NFKC', text)\n",
    "    \n",
    "    # Remove excessive whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Multiple spaces/tabs/newlines to single space\n",
    "    text = text.strip()  # Remove leading/trailing whitespace\n",
    "    \n",
    "    return text if text else None\n",
    "\n",
    "\n",
    "def clean_title(title):\n",
    "    \"\"\"\n",
    "    Clean article titles\n",
    "    \"\"\"\n",
    "    cleaned = clean_text(title)\n",
    "    if not cleaned:\n",
    "        return None\n",
    "    \n",
    "    # Remove any trailing punctuation duplicates\n",
    "    cleaned = re.sub(r'([.!?])\\1+', r'\\1', cleaned)\n",
    "    \n",
    "    return cleaned\n",
    "\n",
    "\n",
    "def clean_description(description):\n",
    "    \"\"\"\n",
    "    Clean article descriptions/summaries\n",
    "    \"\"\"\n",
    "    cleaned = clean_text(description)\n",
    "    if not cleaned:\n",
    "        return None\n",
    "    \n",
    "    # Remove common boilerplate patterns (if any appear)\n",
    "    boilerplate_patterns = [\n",
    "        r'^Published on.*?:',\n",
    "        r'Subscribe to The Hindu.*',\n",
    "        r'Read more at.*',\n",
    "    ]\n",
    "    \n",
    "    for pattern in boilerplate_patterns:\n",
    "        cleaned = re.sub(pattern, '', cleaned, flags=re.IGNORECASE)\n",
    "    \n",
    "    cleaned = cleaned.strip()\n",
    "    return cleaned if cleaned else None\n",
    "\n",
    "\n",
    "def clean_content(content):\n",
    "    \"\"\"\n",
    "    Clean full article content\n",
    "    \"\"\"\n",
    "    cleaned = clean_text(content)\n",
    "    if not cleaned:\n",
    "        return None\n",
    "    \n",
    "    # Remove common content artifacts\n",
    "    # Remove single letters at start (like \"S\" in Row 8)\n",
    "    if len(cleaned) > 2 and cleaned[0].isupper() and cleaned[1] == ' ':\n",
    "        cleaned = cleaned[2:].strip()\n",
    "    \n",
    "    # Remove boilerplate patterns\n",
    "    boilerplate_patterns = [\n",
    "        r'^Published on.*?:',\n",
    "        r'Subscribe to The Hindu.*',\n",
    "        r'Read the full story.*',\n",
    "        r'\\[Total length:.*?\\]',\n",
    "    ]\n",
    "    \n",
    "    for pattern in boilerplate_patterns:\n",
    "        cleaned = re.sub(pattern, '', cleaned, flags=re.IGNORECASE)\n",
    "    \n",
    "    cleaned = cleaned.strip()\n",
    "    return cleaned if cleaned else None\n",
    "\n",
    "\n",
    "def standardize_category(category):\n",
    "    \"\"\"\n",
    "    Standardize category names\n",
    "    \"\"\"\n",
    "    if pd.isna(category) or category is None or category == '':\n",
    "        return None\n",
    "    \n",
    "    # Convert to string and clean\n",
    "    category = str(category).strip()\n",
    "    \n",
    "    # Standardize capitalization (Title Case)\n",
    "    category = category.title()\n",
    "    \n",
    "    # Fix common variations/typos\n",
    "    category_mapping = {\n",
    "        'Tamilnadu': 'Tamil Nadu',\n",
    "        'Tn': 'Tamil Nadu',\n",
    "        'Cbe': 'Coimbatore',\n",
    "        'Mdu': 'Madurai',\n",
    "        'Chn': 'Chennai',\n",
    "    }\n",
    "    \n",
    "    for wrong, right in category_mapping.items():\n",
    "        if category.lower() == wrong.lower():\n",
    "            category = right\n",
    "    \n",
    "    return category\n",
    "\n",
    "\n",
    "print(\"‚úÖ Cleaning functions defined:\")\n",
    "print(\"   - clean_text(text)\")\n",
    "print(\"   - clean_title(title)\")\n",
    "print(\"   - clean_description(description)\")\n",
    "print(\"   - clean_content(content)\")\n",
    "print(\"   - standardize_category(category)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9688fdda-3ff4-41b2-b415-654a83a0887a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cleaning applied to all 10 rows\n",
      "\n",
      "üìä Cleaning Results:\n",
      "   - Rows with cleaned title: 10 / 10\n",
      "   - Rows with cleaned description: 5 / 10\n",
      "   - Rows with cleaned content: 5 / 10\n",
      "   - Rows with cleaned category: 10 / 10\n",
      "   - Rows with has_content=True: 10 / 10\n",
      "   - Rows needing full scrape: 0 / 10\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Apply cleaning functions to all 10 rows\n",
    "\n",
    "# Create cleaned columns\n",
    "sample_df['title_clean'] = sample_df['title'].apply(clean_title)\n",
    "sample_df['description_clean'] = sample_df['description'].apply(clean_description)\n",
    "sample_df['content_clean'] = sample_df['content_full'].apply(clean_content)\n",
    "sample_df['category_clean'] = sample_df['category'].apply(standardize_category)\n",
    "\n",
    "# Check for has_content flag\n",
    "sample_df['has_content'] = (\n",
    "    (sample_df['description_clean'].notna()) | \n",
    "    (sample_df['content_clean'].notna())\n",
    ")\n",
    "\n",
    "# Flag rows needing full scrape\n",
    "sample_df['needs_full_scrape'] = (\n",
    "    (sample_df['description_clean'].isna()) & \n",
    "    (sample_df['content_clean'].isna())\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Cleaning applied to all 10 rows\")\n",
    "print(f\"\\nüìä Cleaning Results:\")\n",
    "print(f\"   - Rows with cleaned title: {sample_df['title_clean'].notna().sum()} / {len(sample_df)}\")\n",
    "print(f\"   - Rows with cleaned description: {sample_df['description_clean'].notna().sum()} / {len(sample_df)}\")\n",
    "print(f\"   - Rows with cleaned content: {sample_df['content_clean'].notna().sum()} / {len(sample_df)}\")\n",
    "print(f\"   - Rows with cleaned category: {sample_df['category_clean'].notna().sum()} / {len(sample_df)}\")\n",
    "print(f\"   - Rows with has_content=True: {sample_df['has_content'].sum()} / {len(sample_df)}\")\n",
    "print(f\"   - Rows needing full scrape: {sample_df['needs_full_scrape'].sum()} / {len(sample_df)}\")\n",
    "\n",
    "# Show flagged rows\n",
    "if sample_df['needs_full_scrape'].sum() > 0:\n",
    "    flagged = sample_df[sample_df['needs_full_scrape']]\n",
    "    print(f\"\\n‚ö†Ô∏è  FLAGGED: {len(flagged)} rows need full scraping\")\n",
    "    print(\"   IDs:\", flagged['id'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4709f2ad-ff19-4f3d-a0de-1a9786afe073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CLEANED DATA - VERIFICATION\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "ROW 1 | ID: 41eb8377-f89f-499a-8f3a-212e537b42de | SOURCE: The Hindu - RSS\n",
      "================================================================================\n",
      "\n",
      "üìå TITLE_CLEAN:\n",
      "Orange alert issued in north Tamil Nadu districts as Cyclone Montha advances\n",
      "\n",
      "üìÅ CATEGORY_CLEAN:\n",
      "Tamil Nadu\n",
      "\n",
      "üìù DESCRIPTION_CLEAN:\n",
      "In its Nowcast till 1 p.m. on Monday (October 27), the RMC has predicted moderate rains to continue over Chennai and its neighbouring districts, and Villupuram and Ranipet\n",
      "\n",
      "üìÑ CONTENT_CLEAN:\n",
      "‚ùå NULL (No content)\n",
      "\n",
      "‚úÖ HAS_CONTENT: True\n",
      "‚ö†Ô∏è  NEEDS_FULL_SCRAPE: False\n",
      "\n",
      "================================================================================\n",
      "ROW 2 | ID: 6067d8d8-dff9-47c8-8121-b6ea7fa6f619 | SOURCE: The Hindu - RSS\n",
      "================================================================================\n",
      "\n",
      "üìå TITLE_CLEAN:\n",
      "Kalaignar International Convention Centre set for completion by February 2026: Minister E.V. Velu\n",
      "\n",
      "üìÅ CATEGORY_CLEAN:\n",
      "Chennai\n",
      "\n",
      "üìù DESCRIPTION_CLEAN:\n",
      "The Public Works Department started the ‚Çπ525-crore project in May this year\n",
      "\n",
      "üìÑ CONTENT_CLEAN:\n",
      "‚ùå NULL (No content)\n",
      "\n",
      "‚úÖ HAS_CONTENT: True\n",
      "‚ö†Ô∏è  NEEDS_FULL_SCRAPE: False\n",
      "\n",
      "================================================================================\n",
      "ROW 3 | ID: 7c9518c5-2224-4cd6-afc5-4318c78237c7 | SOURCE: The Hindu - RSS\n",
      "================================================================================\n",
      "\n",
      "üìå TITLE_CLEAN:\n",
      "Eminent plastic surgeon K. Mathangi Ramakrishnan no more\n",
      "\n",
      "üìÅ CATEGORY_CLEAN:\n",
      "Tamil Nadu\n",
      "\n",
      "üìù DESCRIPTION_CLEAN:\n",
      "She established the plastic surgery department and burns unit at Government Kilpauk Medical College, Chennai ‚Äî one of the foremost government centres in India dedicated to comprehensive burn care and rehabilitation\n",
      "\n",
      "üìÑ CONTENT_CLEAN:\n",
      "‚ùå NULL (No content)\n",
      "\n",
      "‚úÖ HAS_CONTENT: True\n",
      "‚ö†Ô∏è  NEEDS_FULL_SCRAPE: False\n",
      "\n",
      "================================================================================\n",
      "ROW 4 | ID: a29498b2-9a64-4e13-b78b-7edd00272200 | SOURCE: The Hindu - RSS\n",
      "================================================================================\n",
      "\n",
      "üìå TITLE_CLEAN:\n",
      "What is the problem faced by paddy farmers of Tamil Nadu? | Explained\n",
      "\n",
      "üìÅ CATEGORY_CLEAN:\n",
      "Tamil Nadu\n",
      "\n",
      "üìù DESCRIPTION_CLEAN:\n",
      "Why are there issues with procuring and storing paddy from the Cauvery delta?\n",
      "\n",
      "üìÑ CONTENT_CLEAN:\n",
      "‚ùå NULL (No content)\n",
      "\n",
      "‚úÖ HAS_CONTENT: True\n",
      "‚ö†Ô∏è  NEEDS_FULL_SCRAPE: False\n",
      "\n",
      "================================================================================\n",
      "ROW 5 | ID: c468b884-94b3-4973-9f05-6601255010c7 | SOURCE: The Hindu - RSS\n",
      "================================================================================\n",
      "\n",
      "üìå TITLE_CLEAN:\n",
      "BM reviews works in Adyar estuary\n",
      "\n",
      "üìÅ CATEGORY_CLEAN:\n",
      "Tamil Nadu\n",
      "\n",
      "üìù DESCRIPTION_CLEAN:\n",
      "Besides the widening and desilting of Adyar estuary, the CM instructed officials to undertake the widening and desilting works in Cooum, Muttukadu and Ennore estuaries\n",
      "\n",
      "üìÑ CONTENT_CLEAN:\n",
      "‚ùå NULL (No content)\n",
      "\n",
      "‚úÖ HAS_CONTENT: True\n",
      "‚ö†Ô∏è  NEEDS_FULL_SCRAPE: False\n",
      "\n",
      "================================================================================\n",
      "ROW 6 | ID: 9b5243c4-5ef7-4847-9efb-277da6f2ba33 | SOURCE: The Hindu - Archive\n",
      "================================================================================\n",
      "\n",
      "üìå TITLE_CLEAN:\n",
      "Wild elephants damage 30 coconut trees near Coimbatore\n",
      "\n",
      "üìÅ CATEGORY_CLEAN:\n",
      "Coimbatore\n",
      "\n",
      "üìù DESCRIPTION_CLEAN:\n",
      "‚ùå NULL (No description)\n",
      "\n",
      "üìÑ CONTENT_CLEAN:\n",
      "Wild elephants damaged 30 coconut trees at a farm in Dhaliyur near Thondamuthur in Coimbatore district on Monday night. The elephants entered the nine-acre farm, belonging to N. Suganya and Senthil Nathan, from an adjacent farm after crop raiding. The elephants damaged a solar fencing to enter the coconut farm, where they damaged 30 trees aged between two and four years. According to Ms. Suganya, the farm is located around 500 metres from the forest boundary. Elephants damaged four coconut trees...\n",
      "[Total length: 990 characters]\n",
      "\n",
      "‚úÖ HAS_CONTENT: True\n",
      "‚ö†Ô∏è  NEEDS_FULL_SCRAPE: False\n",
      "\n",
      "================================================================================\n",
      "ROW 7 | ID: 5af5e88a-b15f-4e5e-a15e-ce61a777abeb | SOURCE: The Hindu - Archive\n",
      "================================================================================\n",
      "\n",
      "üìå TITLE_CLEAN:\n",
      "Welfare assistance distributed to over 1,500 beneficiaries in Salem district\n",
      "\n",
      "üìÅ CATEGORY_CLEAN:\n",
      "Coimbatore\n",
      "\n",
      "üìù DESCRIPTION_CLEAN:\n",
      "‚ùå NULL (No description)\n",
      "\n",
      "üìÑ CONTENT_CLEAN:\n",
      "Minister for Public Works, E. V. Velu, and Minister for Tourism, R. Rajendran, distributed welfare assistance worth ‚Çπ10.66 crore to 1,572 beneficiaries, including women, self-help groups (SHGs), differently-abled persons and widows, here on Tuesday (September 30, 2025). At a function organised by the Salem District Central Cooperative Bank, Mr. Velu said that former Chief Minister M. Karunanidhi had introduced landmark welfare schemes, including waiver of cooperative jewellery loans worth ‚Çπ7,000...\n",
      "[Total length: 1993 characters]\n",
      "\n",
      "‚úÖ HAS_CONTENT: True\n",
      "‚ö†Ô∏è  NEEDS_FULL_SCRAPE: False\n",
      "\n",
      "================================================================================\n",
      "ROW 8 | ID: 2176067d-6e1c-42d8-a71e-4813e5e76331 | SOURCE: The Hindu - Archive\n",
      "================================================================================\n",
      "\n",
      "üìå TITLE_CLEAN:\n",
      "Garland from Srivilliputtur Andal Temple taken to Tirumala\n",
      "\n",
      "üìÅ CATEGORY_CLEAN:\n",
      "Madurai\n",
      "\n",
      "üìù DESCRIPTION_CLEAN:\n",
      "‚ùå NULL (No description)\n",
      "\n",
      "üìÑ CONTENT_CLEAN:\n",
      "After performing special pujas, priests from the Andal Temple here carried garland and vasthram, among other offerings, to the presiding deity in Tirumala on Sunday, where the annual brahmotsavam is being held as part of Purattasi month. The rituals commenced with special pujas to the deity here in the presence of HR&CE officials and members of the Board of Trustees on Friday. Devotees chanting ‚ÄòGovinda, Govinda‚Äô went around the temple when the garland was being carried in a procession by senior...\n",
      "[Total length: 663 characters]\n",
      "\n",
      "‚úÖ HAS_CONTENT: True\n",
      "‚ö†Ô∏è  NEEDS_FULL_SCRAPE: False\n",
      "\n",
      "================================================================================\n",
      "ROW 9 | ID: 3701bf78-4227-4f6d-bd8b-2dfa1bc2f06f | SOURCE: The Hindu - Archive\n",
      "================================================================================\n",
      "\n",
      "üìå TITLE_CLEAN:\n",
      "85 establishments booked for working on Gandhi Jayanthi in Erode\n",
      "\n",
      "üìÅ CATEGORY_CLEAN:\n",
      "Coimbatore\n",
      "\n",
      "üìù DESCRIPTION_CLEAN:\n",
      "‚ùå NULL (No description)\n",
      "\n",
      "üìÑ CONTENT_CLEAN:\n",
      "The Labour Department has registered cases against 85 shops, eateries, commercial establishments, and transport companies for not declaring a holiday for employees on October 2 (Thursday), Gandhi Jayanthi and for not paying them double wages. In a release, K. Jeyalakshmi, Assistant Commissioner of Labour (Enforcement), said officials inspected 106 establishments in Erode, Bhavani, Perundurai, Gobichettipalayam, and Sathyamangalam on Thursday. Of these, 85 neither declared a holiday for employees...\n",
      "[Total length: 825 characters]\n",
      "\n",
      "‚úÖ HAS_CONTENT: True\n",
      "‚ö†Ô∏è  NEEDS_FULL_SCRAPE: False\n",
      "\n",
      "================================================================================\n",
      "ROW 10 | ID: 2f4a683d-31a7-4d8e-8961-fa97490a83d3 | SOURCE: The Hindu - Archive\n",
      "================================================================================\n",
      "\n",
      "üìå TITLE_CLEAN:\n",
      "PenmAI draws huge turnout of women from southern districts held at TSM\n",
      "\n",
      "üìÅ CATEGORY_CLEAN:\n",
      "Madurai\n",
      "\n",
      "üìù DESCRIPTION_CLEAN:\n",
      "‚ùå NULL (No description)\n",
      "\n",
      "üìÑ CONTENT_CLEAN:\n",
      "PenmAI 2025, a first of its kind AI (artificial intelligence) upskilling workshop was organised at the Thiagarajar School of Management. A day-long workshop dedicated exclusively to empowering women through AI drew a huge turnout from many southern districts. The Incubation Center of TSM, in collaboration with Google, StartupTN and Google Developers aimed to upskill 2,025 women in the year 2025, symbolising inclusivity and innovation. Surpassing expectations, over 2,500 women participants from a...\n",
      "[Total length: 1512 characters]\n",
      "\n",
      "‚úÖ HAS_CONTENT: True\n",
      "‚ö†Ô∏è  NEEDS_FULL_SCRAPE: False\n",
      "\n",
      "================================================================================\n",
      "END OF CLEANED DATA\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Display cleaned text for verification\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"CLEANED DATA - VERIFICATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for idx, row in sample_df.iterrows():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ROW {idx + 1} | ID: {row['id']} | SOURCE: {row['source']}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    print(f\"\\nüìå TITLE_CLEAN:\")\n",
    "    print(f\"{row['title_clean']}\")\n",
    "    \n",
    "    print(f\"\\nüìÅ CATEGORY_CLEAN:\")\n",
    "    print(f\"{row['category_clean']}\")\n",
    "    \n",
    "    print(f\"\\nüìù DESCRIPTION_CLEAN:\")\n",
    "    if pd.notna(row['description_clean']):\n",
    "        print(f\"{row['description_clean']}\")\n",
    "    else:\n",
    "        print(\"‚ùå NULL (No description)\")\n",
    "    \n",
    "    print(f\"\\nüìÑ CONTENT_CLEAN:\")\n",
    "    if pd.notna(row['content_clean']):\n",
    "        print(f\"{row['content_clean'][:500]}...\")\n",
    "        print(f\"[Total length: {len(row['content_clean'])} characters]\")\n",
    "    else:\n",
    "        print(\"‚ùå NULL (No content)\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ HAS_CONTENT: {row['has_content']}\")\n",
    "    print(f\"‚ö†Ô∏è  NEEDS_FULL_SCRAPE: {row['needs_full_scrape']}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"END OF CLEANED DATA\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ebceab5-4f3f-4c55-b095-4dd35a63527c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CLEANING ISSUES DOCUMENTATION\n",
      "================================================================================\n",
      "\n",
      "‚úÖ No title cleaning issues\n",
      "\n",
      "‚úÖ Category Standardization:\n",
      "category_clean\n",
      "Tamil Nadu    4\n",
      "Coimbatore    3\n",
      "Madurai       2\n",
      "Chennai       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "‚úÖ All rows have content\n",
      "\n",
      "üìè Character Length Comparison:\n",
      "\n",
      "Title:\n",
      "   Raw: avg=65.3\n",
      "   Clean: avg=65.3\n",
      "\n",
      "Description:\n",
      "   Raw: avg=70.4\n",
      "   Clean: avg=70.4\n",
      "\n",
      "Content:\n",
      "   Raw: avg=598.5\n",
      "   Clean: avg=598.3\n",
      "\n",
      "================================================================================\n",
      "SUMMARY OF ISSUES\n",
      "================================================================================\n",
      "‚úÖ No critical issues found!\n",
      "\n",
      "üìä Final Statistics:\n",
      "   - Total rows processed: 10\n",
      "   - Rows with content: 10\n",
      "   - Rows needing scraping: 0\n",
      "   - Success rate: 100.0%\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Document cleaning issues and statistics\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"CLEANING ISSUES DOCUMENTATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "issues_found = []\n",
    "\n",
    "# Check 1: Title cleaning\n",
    "title_issues = sample_df[sample_df['title_clean'].isna()]\n",
    "if len(title_issues) > 0:\n",
    "    issues_found.append(f\"‚ö†Ô∏è  {len(title_issues)} rows with NULL title after cleaning\")\n",
    "    print(f\"\\n‚ö†Ô∏è  Title Issues: {len(title_issues)} rows\")\n",
    "    print(\"   IDs:\", title_issues['id'].tolist())\n",
    "else:\n",
    "    print(f\"\\n‚úÖ No title cleaning issues\")\n",
    "\n",
    "# Check 2: Category standardization\n",
    "print(f\"\\n‚úÖ Category Standardization:\")\n",
    "print(sample_df['category_clean'].value_counts())\n",
    "\n",
    "# Check 3: Content availability\n",
    "no_content = sample_df[sample_df['needs_full_scrape']]\n",
    "if len(no_content) > 0:\n",
    "    issues_found.append(f\"‚ö†Ô∏è  {len(no_content)} rows with NO content (need full scraping)\")\n",
    "    print(f\"\\n‚ö†Ô∏è  Content Issues: {len(no_content)} rows need full scraping\")\n",
    "    print(\"   IDs:\", no_content['id'].tolist())\n",
    "else:\n",
    "    print(f\"\\n‚úÖ All rows have content\")\n",
    "\n",
    "# Check 4: Character length comparison (before/after)\n",
    "print(f\"\\nüìè Character Length Comparison:\")\n",
    "sample_df['title_clean_length'] = sample_df['title_clean'].fillna('').str.len()\n",
    "sample_df['desc_clean_length'] = sample_df['description_clean'].fillna('').str.len()\n",
    "sample_df['content_clean_length'] = sample_df['content_clean'].fillna('').str.len()\n",
    "\n",
    "print(f\"\\nTitle:\")\n",
    "print(f\"   Raw: avg={sample_df['title_length'].mean():.1f}\")\n",
    "print(f\"   Clean: avg={sample_df['title_clean_length'].mean():.1f}\")\n",
    "\n",
    "print(f\"\\nDescription:\")\n",
    "print(f\"   Raw: avg={sample_df['desc_length'].mean():.1f}\")\n",
    "print(f\"   Clean: avg={sample_df['desc_clean_length'].mean():.1f}\")\n",
    "\n",
    "print(f\"\\nContent:\")\n",
    "print(f\"   Raw: avg={sample_df['content_length'].mean():.1f}\")\n",
    "print(f\"   Clean: avg={sample_df['content_clean_length'].mean():.1f}\")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"SUMMARY OF ISSUES\")\n",
    "print(f\"{'='*80}\")\n",
    "if issues_found:\n",
    "    for issue in issues_found:\n",
    "        print(issue)\n",
    "else:\n",
    "    print(\"‚úÖ No critical issues found!\")\n",
    "\n",
    "print(f\"\\nüìä Final Statistics:\")\n",
    "print(f\"   - Total rows processed: {len(sample_df)}\")\n",
    "print(f\"   - Rows with content: {sample_df['has_content'].sum()}\")\n",
    "print(f\"   - Rows needing scraping: {sample_df['needs_full_scrape'].sum()}\")\n",
    "print(f\"   - Success rate: {(sample_df['has_content'].sum() / len(sample_df) * 100):.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5ad1fd-1a20-440d-b8fc-b01373fcd624",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13",
   "language": "python",
   "name": "python313"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
