{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4a25a6d-a0a5-4ee8-91cd-bfcf074b7ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Environment loaded successfully\n",
      "📊 Supabase URL: https://lgnhjzlbezpczlobeevu.s...\n",
      "🔑 API Key loaded: 208 characters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import html\n",
    "import unicodedata\n",
    "from dotenv import load_dotenv\n",
    "from supabase import create_client, Client\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# Initialize Supabase client\n",
    "SUPABASE_URL = \"https://lgnhjzlbezpczlobeevu.supabase.co\"\n",
    "SUPABASE_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImxnbmhqemxiZXpwY3psb2JlZXZ1Iiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTgyMDgzNjcsImV4cCI6MjA3Mzc4NDM2N30.O5Yt0dOyYq326ESo0LBL7lGj4k8zwpuodJfTtGwrPek\"\n",
    "\n",
    "\n",
    "if not SUPABASE_URL or not SUPABASE_KEY:\n",
    "    raise ValueError(\"Missing Supabase credentials in .env file\")\n",
    "\n",
    "supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)\n",
    "\n",
    "print(\"✅ Environment loaded successfully\")\n",
    "print(f\"📊 Supabase URL: {SUPABASE_URL[:30]}...\")\n",
    "print(f\"🔑 API Key loaded: {len(SUPABASE_KEY)} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af65d23f-29d5-4950-8f7d-589c76670df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully connected to Supabase\n",
      "📈 Total rows in news_raw: 745\n",
      "\n",
      "📊 Data Breakdown:\n",
      "   - RSS articles: 100\n",
      "   - Archive articles: 645\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Get total count\n",
    "    response = supabase.table('news_cleaned').select('id', count='exact').execute()\n",
    "    \n",
    "    print(f\"✅ Successfully connected to Supabase\")\n",
    "    print(f\"📈 Total rows in news_cleaned: {total_count}\")\n",
    "    \n",
    "    # Get breakdown by source\n",
    "    rss_response = supabase.table('news_cleaned').select('id', count='exact').eq('source', 'The Hindu - RSS').execute()\n",
    "    archive_response = supabase.table('news_cleaned').select('id', count='exact').eq('source', 'The Hindu - Archive').execute()\n",
    "    \n",
    "    print(f\"\\n📊 Data Breakdown:\")\n",
    "    print(f\"   - RSS articles: {rss_response.count}\")\n",
    "    print(f\"   - Archive articles: {archive_response.count}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error connecting to Supabase: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ca309e5-20e3-4627-aee0-e898082a33de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Retrieved 10 rows for testing\n",
      "   - RSS: 5 rows\n",
      "   - Archive: 5 rows\n",
      "\n",
      "📋 Sample DataFrame shape: (10, 9)\n",
      "\n",
      "🔍 Columns: ['id', 'title', 'description', 'content_full', 'category', 'source', 'link', 'pub_date', 'archive_date']\n"
     ]
    }
   ],
   "source": [
    "# Fetch 5 RSS articles\n",
    "rss_sample = supabase.table('news_cleaned')\\\n",
    "    .select('id, title, description, content_full, category, source, link, pub_date, archive_date')\\\n",
    "    .eq('source', 'The Hindu - RSS')\\\n",
    "    .limit(5)\\\n",
    "    .execute()\n",
    "\n",
    "# Fetch 5 Archive articles\n",
    "archive_sample = supabase.table('news_cleaned')\\\n",
    "    .select('id, title, description, content_full, category, source, link, pub_date, archive_date')\\\n",
    "    .eq('source', 'The Hindu - Archive')\\\n",
    "    .limit(5)\\\n",
    "    .execute()\n",
    "\n",
    "# Combine into DataFrame\n",
    "rss_df = pd.DataFrame(rss_sample.data)\n",
    "archive_df = pd.DataFrame(archive_sample.data)\n",
    "sample_df = pd.concat([rss_df, archive_df], ignore_index=True)\n",
    "\n",
    "print(f\"✅ Retrieved {len(sample_df)} rows for testing\")\n",
    "print(f\"   - RSS: {len(rss_df)} rows\")\n",
    "print(f\"   - Archive: {len(archive_df)} rows\")\n",
    "print(f\"\\n📋 Sample DataFrame shape: {sample_df.shape}\")\n",
    "print(f\"\\n🔍 Columns: {list(sample_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03c8e3f7-5913-440f-a0f7-f18fd6afff0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "RAW DATA SAMPLE - MANUAL VERIFICATION\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "ROW 1 | ID: 41eb8377-f89f-499a-8f3a-212e537b42de | SOURCE: The Hindu - RSS\n",
      "================================================================================\n",
      "\n",
      "📌 TITLE:\n",
      "Orange alert issued in north Tamil Nadu districts as Cyclone Montha advances\n",
      "\n",
      "📁 CATEGORY:\n",
      "Tamil Nadu\n",
      "\n",
      "📝 DESCRIPTION:\n",
      "In its Nowcast till 1 p.m. on Monday (October 27), the RMC has predicted moderate rains to continue over Chennai and its neighbouring districts, and Villupuram and Ranipet\n",
      "\n",
      "📄 CONTENT_FULL:\n",
      "❌ EMPTY/NULL\n",
      "\n",
      "🔗 LINK: https://www.thehindu.com/news/national/tamil-nadu/cyclone-montha-orange-alert-issued-in-north-tamil-nadu-districts-as-weather-system-advances/article70207325.ece\n",
      "📅 PUB_DATE: 2025-10-27T12:23:45+00:00\n",
      "📅 ARCHIVE_DATE: None\n",
      "\n",
      "================================================================================\n",
      "ROW 2 | ID: 6067d8d8-dff9-47c8-8121-b6ea7fa6f619 | SOURCE: The Hindu - RSS\n",
      "================================================================================\n",
      "\n",
      "📌 TITLE:\n",
      "Kalaignar International Convention Centre set for completion by February 2026: Minister E.V. Velu\n",
      "\n",
      "📁 CATEGORY:\n",
      "Chennai\n",
      "\n",
      "📝 DESCRIPTION:\n",
      "The Public Works Department started the ₹525-crore project in May this year\n",
      "\n",
      "📄 CONTENT_FULL:\n",
      "❌ EMPTY/NULL\n",
      "\n",
      "🔗 LINK: https://www.thehindu.com/news/cities/chennai/kalaignar-international-convention-centre-set-for-completion-by-february-2026-minister-ev-velu/article70207237.ece\n",
      "📅 PUB_DATE: 2025-10-27T11:59:34+00:00\n",
      "📅 ARCHIVE_DATE: None\n",
      "\n",
      "================================================================================\n",
      "ROW 3 | ID: 7c9518c5-2224-4cd6-afc5-4318c78237c7 | SOURCE: The Hindu - RSS\n",
      "================================================================================\n",
      "\n",
      "📌 TITLE:\n",
      "Eminent plastic surgeon K. Mathangi Ramakrishnan no more\n",
      "\n",
      "📁 CATEGORY:\n",
      "Tamil Nadu\n",
      "\n",
      "📝 DESCRIPTION:\n",
      "She established the plastic surgery department and burns unit at Government Kilpauk Medical College, Chennai — one of the foremost government centres in India dedicated to comprehensive burn care and rehabilitation\n",
      "\n",
      "📄 CONTENT_FULL:\n",
      "❌ EMPTY/NULL\n",
      "\n",
      "🔗 LINK: https://www.thehindu.com/news/national/tamil-nadu/eminent-plastic-surgeon-k-mathangi-ramakrishnan-no-more/article70207162.ece\n",
      "📅 PUB_DATE: 2025-10-27T11:09:02+00:00\n",
      "📅 ARCHIVE_DATE: None\n",
      "\n",
      "================================================================================\n",
      "ROW 4 | ID: a29498b2-9a64-4e13-b78b-7edd00272200 | SOURCE: The Hindu - RSS\n",
      "================================================================================\n",
      "\n",
      "📌 TITLE:\n",
      "What is the problem faced by paddy farmers of Tamil Nadu? | Explained\n",
      "\n",
      "📁 CATEGORY:\n",
      "Tamil Nadu\n",
      "\n",
      "📝 DESCRIPTION:\n",
      "Why are there issues with procuring and storing paddy from the Cauvery delta?\n",
      "\n",
      "📄 CONTENT_FULL:\n",
      "❌ EMPTY/NULL\n",
      "\n",
      "🔗 LINK: https://www.thehindu.com/news/national/tamil-nadu/what-is-the-problem-faced-by-paddy-farmers-of-tamil-nadu-explained/article70206033.ece\n",
      "📅 PUB_DATE: 2025-10-27T08:30:00+00:00\n",
      "📅 ARCHIVE_DATE: None\n",
      "\n",
      "================================================================================\n",
      "ROW 5 | ID: c468b884-94b3-4973-9f05-6601255010c7 | SOURCE: The Hindu - RSS\n",
      "================================================================================\n",
      "\n",
      "📌 TITLE:\n",
      "BM reviews works in Adyar estuary\n",
      "\n",
      "📁 CATEGORY:\n",
      "Tamil Nadu\n",
      "\n",
      "📝 DESCRIPTION:\n",
      "Besides the widening and desilting of Adyar estuary, the CM instructed officials to undertake the widening and desilting works in Cooum, Muttukadu and Ennore estuaries\n",
      "\n",
      "📄 CONTENT_FULL:\n",
      "❌ EMPTY/NULL\n",
      "\n",
      "🔗 LINK: https://www.thehindu.com/news/national/tamil-nadu/briefly-cm-reviews-works-in-adyar-estuary/article70204360.ece\n",
      "📅 PUB_DATE: 2025-10-27T07:35:37+00:00\n",
      "📅 ARCHIVE_DATE: None\n",
      "\n",
      "================================================================================\n",
      "ROW 6 | ID: 9b5243c4-5ef7-4847-9efb-277da6f2ba33 | SOURCE: The Hindu - Archive\n",
      "================================================================================\n",
      "\n",
      "📌 TITLE:\n",
      "Wild elephants damage 30 coconut trees near Coimbatore\n",
      "\n",
      "📁 CATEGORY:\n",
      "Coimbatore\n",
      "\n",
      "📝 DESCRIPTION:\n",
      "❌ EMPTY/NULL\n",
      "\n",
      "📄 CONTENT_FULL:\n",
      "Wild elephants damaged 30 coconut trees at a farm in Dhaliyur near Thondamuthur in Coimbatore district on Monday night.\n",
      "The elephants entered the nine-acre farm, belonging to N. Suganya and Senthil Nathan, from an adjacent farm after crop raiding. The elephants damaged a solar fencing to enter the coconut farm, where they damaged 30 trees aged between two and four years.\n",
      "According to Ms. Suganya, the farm is located around 500 metres from the forest boundary. Elephants damaged four coconut trees...\n",
      "[Total length: 990 characters]\n",
      "\n",
      "🔗 LINK: https://www.thehindu.com/news/cities/Coimbatore/elephants-damage-30-coconut-trees-near-coimbatore/article70113643.ece\n",
      "📅 PUB_DATE: None\n",
      "📅 ARCHIVE_DATE: 2025-10-01\n",
      "\n",
      "================================================================================\n",
      "ROW 7 | ID: 5af5e88a-b15f-4e5e-a15e-ce61a777abeb | SOURCE: The Hindu - Archive\n",
      "================================================================================\n",
      "\n",
      "📌 TITLE:\n",
      "Welfare assistance distributed to over 1,500 beneficiaries in Salem district\n",
      "\n",
      "📁 CATEGORY:\n",
      "Coimbatore\n",
      "\n",
      "📝 DESCRIPTION:\n",
      "❌ EMPTY/NULL\n",
      "\n",
      "📄 CONTENT_FULL:\n",
      "Minister for Public Works, E. V. Velu, and Minister for Tourism, R. Rajendran, distributed welfare assistance worth ₹10.66 crore to 1,572 beneficiaries, including women, self-help groups (SHGs), differently-abled persons and widows, here on Tuesday (September 30, 2025).\n",
      "At a function organised by the Salem District Central Cooperative Bank, Mr. Velu said that former Chief Minister M. Karunanidhi had introduced landmark welfare schemes, including waiver of cooperative jewellery loans worth ₹7,000...\n",
      "[Total length: 1993 characters]\n",
      "\n",
      "🔗 LINK: https://www.thehindu.com/news/cities/Coimbatore/welfare-assistance-distributed-to-over-1500-beneficiaries-in-salem-district/article70112322.ece\n",
      "📅 PUB_DATE: None\n",
      "📅 ARCHIVE_DATE: 2025-10-01\n",
      "\n",
      "================================================================================\n",
      "ROW 8 | ID: 2176067d-6e1c-42d8-a71e-4813e5e76331 | SOURCE: The Hindu - Archive\n",
      "================================================================================\n",
      "\n",
      "📌 TITLE:\n",
      "Garland from Srivilliputtur Andal Temple taken to Tirumala\n",
      "\n",
      "📁 CATEGORY:\n",
      "Madurai\n",
      "\n",
      "📝 DESCRIPTION:\n",
      "❌ EMPTY/NULL\n",
      "\n",
      "📄 CONTENT_FULL:\n",
      "S\n",
      "After performing special pujas, priests from the Andal Temple here carried garland and vasthram, among other offerings, to the presiding deity in Tirumala on Sunday, where the annual brahmotsavam is being held as part of Purattasi month.\n",
      "The rituals commenced with special pujas to the deity here in the presence of HR&CE officials and members of the Board of Trustees on Friday. Devotees chanting ‘Govinda, Govinda’ went around the temple when the garland was being carried in a procession by seni...\n",
      "[Total length: 665 characters]\n",
      "\n",
      "🔗 LINK: https://www.thehindu.com/news/cities/Madurai/garland-from-srivilliputtur-andal-temple-taken-to-tirumala/article70102659.ece\n",
      "📅 PUB_DATE: None\n",
      "📅 ARCHIVE_DATE: 2025-09-28\n",
      "\n",
      "================================================================================\n",
      "ROW 9 | ID: 3701bf78-4227-4f6d-bd8b-2dfa1bc2f06f | SOURCE: The Hindu - Archive\n",
      "================================================================================\n",
      "\n",
      "📌 TITLE:\n",
      "85 establishments booked for working on Gandhi Jayanthi in Erode\n",
      "\n",
      "📁 CATEGORY:\n",
      "Coimbatore\n",
      "\n",
      "📝 DESCRIPTION:\n",
      "❌ EMPTY/NULL\n",
      "\n",
      "📄 CONTENT_FULL:\n",
      "The Labour Department has registered cases against 85 shops, eateries, commercial establishments, and transport companies for not declaring a holiday for employees on October 2 (Thursday), Gandhi Jayanthi and for not paying them double wages.\n",
      "In a release, K. Jeyalakshmi, Assistant Commissioner of Labour (Enforcement), said officials inspected 106 establishments in Erode, Bhavani, Perundurai, Gobichettipalayam, and Sathyamangalam on Thursday. Of these, 85 neither declared a holiday for employees...\n",
      "[Total length: 825 characters]\n",
      "\n",
      "🔗 LINK: https://www.thehindu.com/news/cities/Coimbatore/85-establishments-booked-for-working-on-gandhi-jayanthi-in-erode/article70117512.ece\n",
      "📅 PUB_DATE: None\n",
      "📅 ARCHIVE_DATE: 2025-10-03\n",
      "\n",
      "================================================================================\n",
      "ROW 10 | ID: 2f4a683d-31a7-4d8e-8961-fa97490a83d3 | SOURCE: The Hindu - Archive\n",
      "================================================================================\n",
      "\n",
      "📌 TITLE:\n",
      "PenmAI draws huge turnout of women from southern districts held at TSM\n",
      "\n",
      "📁 CATEGORY:\n",
      "Madurai\n",
      "\n",
      "📝 DESCRIPTION:\n",
      "❌ EMPTY/NULL\n",
      "\n",
      "📄 CONTENT_FULL:\n",
      "PenmAI 2025, a first of its kind AI (artificial intelligence) upskilling workshop was organised at the Thiagarajar School of Management.\n",
      "A day-long workshop dedicated exclusively to empowering women through AI drew a huge turnout from many southern districts.\n",
      "The Incubation Center of TSM, in collaboration with Google, StartupTN and Google Developers aimed to upskill 2,025 women in the year 2025, symbolising inclusivity and innovation.\n",
      "Surpassing expectations, over 2,500 women participants from a...\n",
      "[Total length: 1512 characters]\n",
      "\n",
      "🔗 LINK: https://www.thehindu.com/news/cities/Madurai/penmai-draws-huge-turnout-of-women-from-southern-districts-held-at-tsm/article70113802.ece\n",
      "📅 PUB_DATE: None\n",
      "📅 ARCHIVE_DATE: 2025-10-01\n",
      "\n",
      "================================================================================\n",
      "END OF RAW DATA SAMPLE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)  # No truncation\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"RAW DATA SAMPLE - MANUAL VERIFICATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for idx, row in sample_df.iterrows():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ROW {idx + 1} | ID: {row['id']} | SOURCE: {row['source']}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    print(f\"\\n📌 TITLE:\")\n",
    "    print(f\"{row['title']}\")\n",
    "    \n",
    "    print(f\"\\n📁 CATEGORY:\")\n",
    "    print(f\"{row['category']}\")\n",
    "    \n",
    "    print(f\"\\n📝 DESCRIPTION:\")\n",
    "    if pd.notna(row['description']) and row['description']:\n",
    "        print(f\"{row['description']}\")\n",
    "    else:\n",
    "        print(\"❌ EMPTY/NULL\")\n",
    "    \n",
    "    print(f\"\\n📄 CONTENT_FULL:\")\n",
    "    if pd.notna(row['content_full']) and row['content_full']:\n",
    "        print(f\"{row['content_full'][:500]}...\")  # Show first 500 chars\n",
    "        print(f\"[Total length: {len(row['content_full'])} characters]\")\n",
    "    else:\n",
    "        print(\"❌ EMPTY/NULL\")\n",
    "    \n",
    "    print(f\"\\n🔗 LINK: {row['link']}\")\n",
    "    print(f\"📅 PUB_DATE: {row['pub_date']}\")\n",
    "    print(f\"📅 ARCHIVE_DATE: {row['archive_date']}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"END OF RAW DATA SAMPLE\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "156d6caa-7d29-4a0c-9ab9-dbcf452ee263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DATA QUALITY ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "📊 Content Availability:\n",
      "   - Rows with description: 5 / 10\n",
      "   - Rows with content_full: 5 / 10\n",
      "   - Rows with BOTH: 0 / 10\n",
      "   - Rows with NEITHER: 0 / 10\n",
      "\n",
      "📂 Category Distribution:\n",
      "category\n",
      "Tamil Nadu    4\n",
      "Coimbatore    3\n",
      "Madurai       2\n",
      "Chennai       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "📏 Text Length Statistics:\n",
      "   Title: min=33, max=97, avg=65.3\n",
      "   Description: min=0, max=214, avg=70.4\n",
      "   Content: min=0, max=1993, avg=598.5\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"DATA QUALITY ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Check for missing content\n",
    "has_description = sample_df['description'].notna() & (sample_df['description'] != '')\n",
    "has_content_full = sample_df['content_full'].notna() & (sample_df['content_full'] != '')\n",
    "\n",
    "print(f\"\\n📊 Content Availability:\")\n",
    "print(f\"   - Rows with description: {has_description.sum()} / {len(sample_df)}\")\n",
    "print(f\"   - Rows with content_full: {has_content_full.sum()} / {len(sample_df)}\")\n",
    "print(f\"   - Rows with BOTH: {(has_description & has_content_full).sum()} / {len(sample_df)}\")\n",
    "print(f\"   - Rows with NEITHER: {(~has_description & ~has_content_full).sum()} / {len(sample_df)}\")\n",
    "\n",
    "# Flag rows with missing content\n",
    "missing_both = sample_df[~has_description & ~has_content_full]\n",
    "if len(missing_both) > 0:\n",
    "    print(f\"\\n⚠️  FLAGGED: {len(missing_both)} rows with NO content\")\n",
    "    print(\"   IDs:\", missing_both['id'].tolist())\n",
    "\n",
    "# Category distribution\n",
    "print(f\"\\n📂 Category Distribution:\")\n",
    "print(sample_df['category'].value_counts())\n",
    "\n",
    "# Character length analysis\n",
    "sample_df['title_length'] = sample_df['title'].fillna('').str.len()\n",
    "sample_df['desc_length'] = sample_df['description'].fillna('').str.len()\n",
    "sample_df['content_length'] = sample_df['content_full'].fillna('').str.len()\n",
    "\n",
    "print(f\"\\n📏 Text Length Statistics:\")\n",
    "print(f\"   Title: min={sample_df['title_length'].min()}, max={sample_df['title_length'].max()}, avg={sample_df['title_length'].mean():.1f}\")\n",
    "print(f\"   Description: min={sample_df['desc_length'].min()}, max={sample_df['desc_length'].max()}, avg={sample_df['desc_length'].mean():.1f}\")\n",
    "print(f\"   Content: min={sample_df['content_length'].min()}, max={sample_df['content_length'].max()}, avg={sample_df['content_length'].mean():.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e8b8038-9aad-49e3-ba62-dc835b038e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaning functions defined:\n",
      "   - clean_text(text)\n",
      "   - clean_title(title)\n",
      "   - clean_description(description)\n",
      "   - clean_content(content)\n",
      "   - standardize_category(category)\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Define text cleaning functions\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    General purpose text cleaner\n",
    "    Handles: None values, whitespace normalization, encoding fixes\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or text is None or text == '':\n",
    "        return None\n",
    "    \n",
    "    # Convert to string\n",
    "    text = str(text)\n",
    "    \n",
    "    # Decode HTML entities (e.g., &amp; -> &, &quot; -> \")\n",
    "    text = html.unescape(text)\n",
    "    \n",
    "    # Fix common encoding issues\n",
    "    encoding_fixes = {\n",
    "        'â€™': \"'\",  # Smart apostrophe\n",
    "        'â€œ': '\"',  # Smart quote open\n",
    "        'â€': '\"',   # Smart quote close\n",
    "        'â€\"': '—',  # Em dash\n",
    "        'â€\"': '–',  # En dash\n",
    "        'Ã¡': 'á',\n",
    "        'Ã©': 'é',\n",
    "        'Ã­': 'í',\n",
    "        'Ã³': 'ó',\n",
    "        'Ãº': 'ú',\n",
    "        'â‚¹': '₹',  # Rupee symbol\n",
    "    }\n",
    "    \n",
    "    for wrong, right in encoding_fixes.items():\n",
    "        text = text.replace(wrong, right)\n",
    "    \n",
    "    # Normalize Unicode characters\n",
    "    text = unicodedata.normalize('NFKC', text)\n",
    "    \n",
    "    # Remove excessive whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Multiple spaces/tabs/newlines to single space\n",
    "    text = text.strip()  # Remove leading/trailing whitespace\n",
    "    \n",
    "    return text if text else None\n",
    "\n",
    "\n",
    "def clean_title(title):\n",
    "    \"\"\"\n",
    "    Clean article titles\n",
    "    \"\"\"\n",
    "    cleaned = clean_text(title)\n",
    "    if not cleaned:\n",
    "        return None\n",
    "    \n",
    "    # Remove any trailing punctuation duplicates\n",
    "    cleaned = re.sub(r'([.!?])\\1+', r'\\1', cleaned)\n",
    "    \n",
    "    return cleaned\n",
    "\n",
    "\n",
    "def clean_description(description):\n",
    "    \"\"\"\n",
    "    Clean article descriptions/summaries\n",
    "    \"\"\"\n",
    "    cleaned = clean_text(description)\n",
    "    if not cleaned:\n",
    "        return None\n",
    "    \n",
    "    # Remove common boilerplate patterns (if any appear)\n",
    "    boilerplate_patterns = [\n",
    "        r'^Published on.*?:',\n",
    "        r'Subscribe to The Hindu.*',\n",
    "        r'Read more at.*',\n",
    "    ]\n",
    "    \n",
    "    for pattern in boilerplate_patterns:\n",
    "        cleaned = re.sub(pattern, '', cleaned, flags=re.IGNORECASE)\n",
    "    \n",
    "    cleaned = cleaned.strip()\n",
    "    return cleaned if cleaned else None\n",
    "\n",
    "\n",
    "def clean_content(content):\n",
    "    \"\"\"\n",
    "    Clean full article content\n",
    "    \"\"\"\n",
    "    cleaned = clean_text(content)\n",
    "    if not cleaned:\n",
    "        return None\n",
    "    \n",
    "    # Remove common content artifacts\n",
    "    # Remove single letters at start (like \"S\" in Row 8)\n",
    "    if len(cleaned) > 2 and cleaned[0].isupper() and cleaned[1] == ' ':\n",
    "        cleaned = cleaned[2:].strip()\n",
    "    \n",
    "    # Remove boilerplate patterns\n",
    "    boilerplate_patterns = [\n",
    "        r'^Published on.*?:',\n",
    "        r'Subscribe to The Hindu.*',\n",
    "        r'Read the full story.*',\n",
    "        r'\\[Total length:.*?\\]',\n",
    "    ]\n",
    "    \n",
    "    for pattern in boilerplate_patterns:\n",
    "        cleaned = re.sub(pattern, '', cleaned, flags=re.IGNORECASE)\n",
    "    \n",
    "    cleaned = cleaned.strip()\n",
    "    return cleaned if cleaned else None\n",
    "\n",
    "\n",
    "def standardize_category(category):\n",
    "    \"\"\"\n",
    "    Standardize category names\n",
    "    \"\"\"\n",
    "    if pd.isna(category) or category is None or category == '':\n",
    "        return None\n",
    "    \n",
    "    # Convert to string and clean\n",
    "    category = str(category).strip()\n",
    "    \n",
    "    # Standardize capitalization (Title Case)\n",
    "    category = category.title()\n",
    "    \n",
    "    # Fix common variations/typos\n",
    "    category_mapping = {\n",
    "        'Tamilnadu': 'Tamil Nadu',\n",
    "        'Tn': 'Tamil Nadu',\n",
    "        'Cbe': 'Coimbatore',\n",
    "        'Mdu': 'Madurai',\n",
    "        'Chn': 'Chennai',\n",
    "    }\n",
    "    \n",
    "    for wrong, right in category_mapping.items():\n",
    "        if category.lower() == wrong.lower():\n",
    "            category = right\n",
    "    \n",
    "    return category\n",
    "\n",
    "\n",
    "print(\"✅ Cleaning functions defined:\")\n",
    "print(\"   - clean_text(text)\")\n",
    "print(\"   - clean_title(title)\")\n",
    "print(\"   - clean_description(description)\")\n",
    "print(\"   - clean_content(content)\")\n",
    "print(\"   - standardize_category(category)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9688fdda-3ff4-41b2-b415-654a83a0887a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaning applied to all 10 rows\n",
      "\n",
      "📊 Cleaning Results:\n",
      "   - Rows with cleaned title: 10 / 10\n",
      "   - Rows with cleaned description: 5 / 10\n",
      "   - Rows with cleaned content: 5 / 10\n",
      "   - Rows with cleaned category: 10 / 10\n",
      "   - Rows with has_content=True: 10 / 10\n",
      "   - Rows needing full scrape: 0 / 10\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Apply cleaning functions to all 10 rows\n",
    "\n",
    "# Create cleaned columns\n",
    "sample_df['title_clean'] = sample_df['title'].apply(clean_title)\n",
    "sample_df['description_clean'] = sample_df['description'].apply(clean_description)\n",
    "sample_df['content_clean'] = sample_df['content_full'].apply(clean_content)\n",
    "sample_df['category_clean'] = sample_df['category'].apply(standardize_category)\n",
    "\n",
    "# Check for has_content flag\n",
    "sample_df['has_content'] = (\n",
    "    (sample_df['description_clean'].notna()) | \n",
    "    (sample_df['content_clean'].notna())\n",
    ")\n",
    "\n",
    "# Flag rows needing full scrape\n",
    "sample_df['needs_full_scrape'] = (\n",
    "    (sample_df['description_clean'].isna()) & \n",
    "    (sample_df['content_clean'].isna())\n",
    ")\n",
    "\n",
    "print(\"✅ Cleaning applied to all 10 rows\")\n",
    "print(f\"\\n📊 Cleaning Results:\")\n",
    "print(f\"   - Rows with cleaned title: {sample_df['title_clean'].notna().sum()} / {len(sample_df)}\")\n",
    "print(f\"   - Rows with cleaned description: {sample_df['description_clean'].notna().sum()} / {len(sample_df)}\")\n",
    "print(f\"   - Rows with cleaned content: {sample_df['content_clean'].notna().sum()} / {len(sample_df)}\")\n",
    "print(f\"   - Rows with cleaned category: {sample_df['category_clean'].notna().sum()} / {len(sample_df)}\")\n",
    "print(f\"   - Rows with has_content=True: {sample_df['has_content'].sum()} / {len(sample_df)}\")\n",
    "print(f\"   - Rows needing full scrape: {sample_df['needs_full_scrape'].sum()} / {len(sample_df)}\")\n",
    "\n",
    "# Show flagged rows\n",
    "if sample_df['needs_full_scrape'].sum() > 0:\n",
    "    flagged = sample_df[sample_df['needs_full_scrape']]\n",
    "    print(f\"\\n⚠️  FLAGGED: {len(flagged)} rows need full scraping\")\n",
    "    print(\"   IDs:\", flagged['id'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4709f2ad-ff19-4f3d-a0de-1a9786afe073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CLEANED DATA - VERIFICATION\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "ROW 1 | ID: 41eb8377-f89f-499a-8f3a-212e537b42de | SOURCE: The Hindu - RSS\n",
      "================================================================================\n",
      "\n",
      "📌 TITLE_CLEAN:\n",
      "Orange alert issued in north Tamil Nadu districts as Cyclone Montha advances\n",
      "\n",
      "📁 CATEGORY_CLEAN:\n",
      "Tamil Nadu\n",
      "\n",
      "📝 DESCRIPTION_CLEAN:\n",
      "In its Nowcast till 1 p.m. on Monday (October 27), the RMC has predicted moderate rains to continue over Chennai and its neighbouring districts, and Villupuram and Ranipet\n",
      "\n",
      "📄 CONTENT_CLEAN:\n",
      "❌ NULL (No content)\n",
      "\n",
      "✅ HAS_CONTENT: True\n",
      "⚠️  NEEDS_FULL_SCRAPE: False\n",
      "\n",
      "================================================================================\n",
      "ROW 2 | ID: 6067d8d8-dff9-47c8-8121-b6ea7fa6f619 | SOURCE: The Hindu - RSS\n",
      "================================================================================\n",
      "\n",
      "📌 TITLE_CLEAN:\n",
      "Kalaignar International Convention Centre set for completion by February 2026: Minister E.V. Velu\n",
      "\n",
      "📁 CATEGORY_CLEAN:\n",
      "Chennai\n",
      "\n",
      "📝 DESCRIPTION_CLEAN:\n",
      "The Public Works Department started the ₹525-crore project in May this year\n",
      "\n",
      "📄 CONTENT_CLEAN:\n",
      "❌ NULL (No content)\n",
      "\n",
      "✅ HAS_CONTENT: True\n",
      "⚠️  NEEDS_FULL_SCRAPE: False\n",
      "\n",
      "================================================================================\n",
      "ROW 3 | ID: 7c9518c5-2224-4cd6-afc5-4318c78237c7 | SOURCE: The Hindu - RSS\n",
      "================================================================================\n",
      "\n",
      "📌 TITLE_CLEAN:\n",
      "Eminent plastic surgeon K. Mathangi Ramakrishnan no more\n",
      "\n",
      "📁 CATEGORY_CLEAN:\n",
      "Tamil Nadu\n",
      "\n",
      "📝 DESCRIPTION_CLEAN:\n",
      "She established the plastic surgery department and burns unit at Government Kilpauk Medical College, Chennai — one of the foremost government centres in India dedicated to comprehensive burn care and rehabilitation\n",
      "\n",
      "📄 CONTENT_CLEAN:\n",
      "❌ NULL (No content)\n",
      "\n",
      "✅ HAS_CONTENT: True\n",
      "⚠️  NEEDS_FULL_SCRAPE: False\n",
      "\n",
      "================================================================================\n",
      "ROW 4 | ID: a29498b2-9a64-4e13-b78b-7edd00272200 | SOURCE: The Hindu - RSS\n",
      "================================================================================\n",
      "\n",
      "📌 TITLE_CLEAN:\n",
      "What is the problem faced by paddy farmers of Tamil Nadu? | Explained\n",
      "\n",
      "📁 CATEGORY_CLEAN:\n",
      "Tamil Nadu\n",
      "\n",
      "📝 DESCRIPTION_CLEAN:\n",
      "Why are there issues with procuring and storing paddy from the Cauvery delta?\n",
      "\n",
      "📄 CONTENT_CLEAN:\n",
      "❌ NULL (No content)\n",
      "\n",
      "✅ HAS_CONTENT: True\n",
      "⚠️  NEEDS_FULL_SCRAPE: False\n",
      "\n",
      "================================================================================\n",
      "ROW 5 | ID: c468b884-94b3-4973-9f05-6601255010c7 | SOURCE: The Hindu - RSS\n",
      "================================================================================\n",
      "\n",
      "📌 TITLE_CLEAN:\n",
      "BM reviews works in Adyar estuary\n",
      "\n",
      "📁 CATEGORY_CLEAN:\n",
      "Tamil Nadu\n",
      "\n",
      "📝 DESCRIPTION_CLEAN:\n",
      "Besides the widening and desilting of Adyar estuary, the CM instructed officials to undertake the widening and desilting works in Cooum, Muttukadu and Ennore estuaries\n",
      "\n",
      "📄 CONTENT_CLEAN:\n",
      "❌ NULL (No content)\n",
      "\n",
      "✅ HAS_CONTENT: True\n",
      "⚠️  NEEDS_FULL_SCRAPE: False\n",
      "\n",
      "================================================================================\n",
      "ROW 6 | ID: 9b5243c4-5ef7-4847-9efb-277da6f2ba33 | SOURCE: The Hindu - Archive\n",
      "================================================================================\n",
      "\n",
      "📌 TITLE_CLEAN:\n",
      "Wild elephants damage 30 coconut trees near Coimbatore\n",
      "\n",
      "📁 CATEGORY_CLEAN:\n",
      "Coimbatore\n",
      "\n",
      "📝 DESCRIPTION_CLEAN:\n",
      "❌ NULL (No description)\n",
      "\n",
      "📄 CONTENT_CLEAN:\n",
      "Wild elephants damaged 30 coconut trees at a farm in Dhaliyur near Thondamuthur in Coimbatore district on Monday night. The elephants entered the nine-acre farm, belonging to N. Suganya and Senthil Nathan, from an adjacent farm after crop raiding. The elephants damaged a solar fencing to enter the coconut farm, where they damaged 30 trees aged between two and four years. According to Ms. Suganya, the farm is located around 500 metres from the forest boundary. Elephants damaged four coconut trees...\n",
      "[Total length: 990 characters]\n",
      "\n",
      "✅ HAS_CONTENT: True\n",
      "⚠️  NEEDS_FULL_SCRAPE: False\n",
      "\n",
      "================================================================================\n",
      "ROW 7 | ID: 5af5e88a-b15f-4e5e-a15e-ce61a777abeb | SOURCE: The Hindu - Archive\n",
      "================================================================================\n",
      "\n",
      "📌 TITLE_CLEAN:\n",
      "Welfare assistance distributed to over 1,500 beneficiaries in Salem district\n",
      "\n",
      "📁 CATEGORY_CLEAN:\n",
      "Coimbatore\n",
      "\n",
      "📝 DESCRIPTION_CLEAN:\n",
      "❌ NULL (No description)\n",
      "\n",
      "📄 CONTENT_CLEAN:\n",
      "Minister for Public Works, E. V. Velu, and Minister for Tourism, R. Rajendran, distributed welfare assistance worth ₹10.66 crore to 1,572 beneficiaries, including women, self-help groups (SHGs), differently-abled persons and widows, here on Tuesday (September 30, 2025). At a function organised by the Salem District Central Cooperative Bank, Mr. Velu said that former Chief Minister M. Karunanidhi had introduced landmark welfare schemes, including waiver of cooperative jewellery loans worth ₹7,000...\n",
      "[Total length: 1993 characters]\n",
      "\n",
      "✅ HAS_CONTENT: True\n",
      "⚠️  NEEDS_FULL_SCRAPE: False\n",
      "\n",
      "================================================================================\n",
      "ROW 8 | ID: 2176067d-6e1c-42d8-a71e-4813e5e76331 | SOURCE: The Hindu - Archive\n",
      "================================================================================\n",
      "\n",
      "📌 TITLE_CLEAN:\n",
      "Garland from Srivilliputtur Andal Temple taken to Tirumala\n",
      "\n",
      "📁 CATEGORY_CLEAN:\n",
      "Madurai\n",
      "\n",
      "📝 DESCRIPTION_CLEAN:\n",
      "❌ NULL (No description)\n",
      "\n",
      "📄 CONTENT_CLEAN:\n",
      "After performing special pujas, priests from the Andal Temple here carried garland and vasthram, among other offerings, to the presiding deity in Tirumala on Sunday, where the annual brahmotsavam is being held as part of Purattasi month. The rituals commenced with special pujas to the deity here in the presence of HR&CE officials and members of the Board of Trustees on Friday. Devotees chanting ‘Govinda, Govinda’ went around the temple when the garland was being carried in a procession by senior...\n",
      "[Total length: 663 characters]\n",
      "\n",
      "✅ HAS_CONTENT: True\n",
      "⚠️  NEEDS_FULL_SCRAPE: False\n",
      "\n",
      "================================================================================\n",
      "ROW 9 | ID: 3701bf78-4227-4f6d-bd8b-2dfa1bc2f06f | SOURCE: The Hindu - Archive\n",
      "================================================================================\n",
      "\n",
      "📌 TITLE_CLEAN:\n",
      "85 establishments booked for working on Gandhi Jayanthi in Erode\n",
      "\n",
      "📁 CATEGORY_CLEAN:\n",
      "Coimbatore\n",
      "\n",
      "📝 DESCRIPTION_CLEAN:\n",
      "❌ NULL (No description)\n",
      "\n",
      "📄 CONTENT_CLEAN:\n",
      "The Labour Department has registered cases against 85 shops, eateries, commercial establishments, and transport companies for not declaring a holiday for employees on October 2 (Thursday), Gandhi Jayanthi and for not paying them double wages. In a release, K. Jeyalakshmi, Assistant Commissioner of Labour (Enforcement), said officials inspected 106 establishments in Erode, Bhavani, Perundurai, Gobichettipalayam, and Sathyamangalam on Thursday. Of these, 85 neither declared a holiday for employees...\n",
      "[Total length: 825 characters]\n",
      "\n",
      "✅ HAS_CONTENT: True\n",
      "⚠️  NEEDS_FULL_SCRAPE: False\n",
      "\n",
      "================================================================================\n",
      "ROW 10 | ID: 2f4a683d-31a7-4d8e-8961-fa97490a83d3 | SOURCE: The Hindu - Archive\n",
      "================================================================================\n",
      "\n",
      "📌 TITLE_CLEAN:\n",
      "PenmAI draws huge turnout of women from southern districts held at TSM\n",
      "\n",
      "📁 CATEGORY_CLEAN:\n",
      "Madurai\n",
      "\n",
      "📝 DESCRIPTION_CLEAN:\n",
      "❌ NULL (No description)\n",
      "\n",
      "📄 CONTENT_CLEAN:\n",
      "PenmAI 2025, a first of its kind AI (artificial intelligence) upskilling workshop was organised at the Thiagarajar School of Management. A day-long workshop dedicated exclusively to empowering women through AI drew a huge turnout from many southern districts. The Incubation Center of TSM, in collaboration with Google, StartupTN and Google Developers aimed to upskill 2,025 women in the year 2025, symbolising inclusivity and innovation. Surpassing expectations, over 2,500 women participants from a...\n",
      "[Total length: 1512 characters]\n",
      "\n",
      "✅ HAS_CONTENT: True\n",
      "⚠️  NEEDS_FULL_SCRAPE: False\n",
      "\n",
      "================================================================================\n",
      "END OF CLEANED DATA\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Display cleaned text for verification\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"CLEANED DATA - VERIFICATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for idx, row in sample_df.iterrows():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ROW {idx + 1} | ID: {row['id']} | SOURCE: {row['source']}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    print(f\"\\n📌 TITLE_CLEAN:\")\n",
    "    print(f\"{row['title_clean']}\")\n",
    "    \n",
    "    print(f\"\\n📁 CATEGORY_CLEAN:\")\n",
    "    print(f\"{row['category_clean']}\")\n",
    "    \n",
    "    print(f\"\\n📝 DESCRIPTION_CLEAN:\")\n",
    "    if pd.notna(row['description_clean']):\n",
    "        print(f\"{row['description_clean']}\")\n",
    "    else:\n",
    "        print(\"❌ NULL (No description)\")\n",
    "    \n",
    "    print(f\"\\n📄 CONTENT_CLEAN:\")\n",
    "    if pd.notna(row['content_clean']):\n",
    "        print(f\"{row['content_clean'][:500]}...\")\n",
    "        print(f\"[Total length: {len(row['content_clean'])} characters]\")\n",
    "    else:\n",
    "        print(\"❌ NULL (No content)\")\n",
    "    \n",
    "    print(f\"\\n✅ HAS_CONTENT: {row['has_content']}\")\n",
    "    print(f\"⚠️  NEEDS_FULL_SCRAPE: {row['needs_full_scrape']}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"END OF CLEANED DATA\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ebceab5-4f3f-4c55-b095-4dd35a63527c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CLEANING ISSUES DOCUMENTATION\n",
      "================================================================================\n",
      "\n",
      "✅ No title cleaning issues\n",
      "\n",
      "✅ Category Standardization:\n",
      "category_clean\n",
      "Tamil Nadu    4\n",
      "Coimbatore    3\n",
      "Madurai       2\n",
      "Chennai       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "✅ All rows have content\n",
      "\n",
      "📏 Character Length Comparison:\n",
      "\n",
      "Title:\n",
      "   Raw: avg=65.3\n",
      "   Clean: avg=65.3\n",
      "\n",
      "Description:\n",
      "   Raw: avg=70.4\n",
      "   Clean: avg=70.4\n",
      "\n",
      "Content:\n",
      "   Raw: avg=598.5\n",
      "   Clean: avg=598.3\n",
      "\n",
      "================================================================================\n",
      "SUMMARY OF ISSUES\n",
      "================================================================================\n",
      "✅ No critical issues found!\n",
      "\n",
      "📊 Final Statistics:\n",
      "   - Total rows processed: 10\n",
      "   - Rows with content: 10\n",
      "   - Rows needing scraping: 0\n",
      "   - Success rate: 100.0%\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Document cleaning issues and statistics\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"CLEANING ISSUES DOCUMENTATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "issues_found = []\n",
    "\n",
    "# Check 1: Title cleaning\n",
    "title_issues = sample_df[sample_df['title_clean'].isna()]\n",
    "if len(title_issues) > 0:\n",
    "    issues_found.append(f\"⚠️  {len(title_issues)} rows with NULL title after cleaning\")\n",
    "    print(f\"\\n⚠️  Title Issues: {len(title_issues)} rows\")\n",
    "    print(\"   IDs:\", title_issues['id'].tolist())\n",
    "else:\n",
    "    print(f\"\\n✅ No title cleaning issues\")\n",
    "\n",
    "# Check 2: Category standardization\n",
    "print(f\"\\n✅ Category Standardization:\")\n",
    "print(sample_df['category_clean'].value_counts())\n",
    "\n",
    "# Check 3: Content availability\n",
    "no_content = sample_df[sample_df['needs_full_scrape']]\n",
    "if len(no_content) > 0:\n",
    "    issues_found.append(f\"⚠️  {len(no_content)} rows with NO content (need full scraping)\")\n",
    "    print(f\"\\n⚠️  Content Issues: {len(no_content)} rows need full scraping\")\n",
    "    print(\"   IDs:\", no_content['id'].tolist())\n",
    "else:\n",
    "    print(f\"\\n✅ All rows have content\")\n",
    "\n",
    "# Check 4: Character length comparison (before/after)\n",
    "print(f\"\\n📏 Character Length Comparison:\")\n",
    "sample_df['title_clean_length'] = sample_df['title_clean'].fillna('').str.len()\n",
    "sample_df['desc_clean_length'] = sample_df['description_clean'].fillna('').str.len()\n",
    "sample_df['content_clean_length'] = sample_df['content_clean'].fillna('').str.len()\n",
    "\n",
    "print(f\"\\nTitle:\")\n",
    "print(f\"   Raw: avg={sample_df['title_length'].mean():.1f}\")\n",
    "print(f\"   Clean: avg={sample_df['title_clean_length'].mean():.1f}\")\n",
    "\n",
    "print(f\"\\nDescription:\")\n",
    "print(f\"   Raw: avg={sample_df['desc_length'].mean():.1f}\")\n",
    "print(f\"   Clean: avg={sample_df['desc_clean_length'].mean():.1f}\")\n",
    "\n",
    "print(f\"\\nContent:\")\n",
    "print(f\"   Raw: avg={sample_df['content_length'].mean():.1f}\")\n",
    "print(f\"   Clean: avg={sample_df['content_clean_length'].mean():.1f}\")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"SUMMARY OF ISSUES\")\n",
    "print(f\"{'='*80}\")\n",
    "if issues_found:\n",
    "    for issue in issues_found:\n",
    "        print(issue)\n",
    "else:\n",
    "    print(\"✅ No critical issues found!\")\n",
    "\n",
    "print(f\"\\n📊 Final Statistics:\")\n",
    "print(f\"   - Total rows processed: {len(sample_df)}\")\n",
    "print(f\"   - Rows with content: {sample_df['has_content'].sum()}\")\n",
    "print(f\"   - Rows needing scraping: {sample_df['needs_full_scrape'].sum()}\")\n",
    "print(f\"   - Success rate: {(sample_df['has_content'].sum() / len(sample_df) * 100):.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5ad1fd-1a20-440d-b8fc-b01373fcd624",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13",
   "language": "python",
   "name": "python313"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
