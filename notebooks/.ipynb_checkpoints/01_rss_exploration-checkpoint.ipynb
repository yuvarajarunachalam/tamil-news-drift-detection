{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5533bfbb-6202-4d42-b078-7a57c767fb46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Libraries imported successfully!\n",
      "feedparser version: 6.0.12\n",
      "pandas version: 2.2.3\n"
     ]
    }
   ],
   "source": [
    "import feedparser\n",
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from dateutil import parser as date_parser\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"📦 Libraries imported successfully!\")\n",
    "print(f\"feedparser version: {feedparser.__version__}\")\n",
    "print(f\"pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98de65f8-6ad8-4274-9f7b-4df4c0296380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Fetching RSS feed from:\n",
      "https://www.thehindu.com/news/national/tamil-nadu/feeder/default.rss\n",
      "\n",
      "Status Code: 200\n",
      "Response Size: 76142 bytes\n",
      "Content Type: application/xml\n",
      "✅ RSS feed fetched successfully!\n"
     ]
    }
   ],
   "source": [
    "# RSS Feed URL\n",
    "RSS_URL = \"https://www.thehindu.com/news/national/tamil-nadu/feeder/default.rss\"\n",
    "\n",
    "print(f\"🔍 Fetching RSS feed from:\\n{RSS_URL}\\n\")\n",
    "\n",
    "# Fetch the feed\n",
    "response = requests.get(RSS_URL, timeout=10)\n",
    "\n",
    "print(f\"Status Code: {response.status_code}\")\n",
    "print(f\"Response Size: {len(response.content)} bytes\")\n",
    "print(f\"Content Type: {response.headers.get('Content-Type')}\")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"✅ RSS feed fetched successfully!\")\n",
    "else:\n",
    "    print(f\"❌ Failed to fetch feed. Status: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f864e5bf-58f9-4c68-8c24-6cf93bcebb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "📰 FEED METADATA\n",
      "============================================================\n",
      "Feed Title: Tamil Nadu Latest News: Today’s Events & Political Developments | The Hindu\n",
      "Feed Link: https://www.thehindu.com/news/national/tamil-nadu/\n",
      "Feed Description: Stay informed about the latest national news and developments in Tamil Nadu. Get comprehensive cover...\n",
      "Last Build Date: N/A\n",
      "Language: en-US\n",
      "\n",
      "📊 Total Entries: 100\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Parse the feed\n",
    "feed = feedparser.parse(RSS_URL)\n",
    "\n",
    "# Feed metadata\n",
    "print(\"=\" * 60)\n",
    "print(\"📰 FEED METADATA\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Feed Title: {feed.feed.get('title', 'N/A')}\")\n",
    "print(f\"Feed Link: {feed.feed.get('link', 'N/A')}\")\n",
    "print(f\"Feed Description: {feed.feed.get('description', 'N/A')[:100]}...\")\n",
    "print(f\"Last Build Date: {feed.feed.get('lastBuildDate', 'N/A')}\")\n",
    "print(f\"Language: {feed.feed.get('language', 'N/A')}\")\n",
    "print(f\"\\n📊 Total Entries: {len(feed.entries)}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9593a00e-ade1-411f-b6e1-8b1b92d7c0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 INSPECTING FIRST ENTRY STRUCTURE\n",
      "\n",
      "Available Keys:\n",
      "  - title\n",
      "  - title_detail\n",
      "  - summary\n",
      "  - summary_detail\n",
      "  - links\n",
      "  - link\n",
      "  - id\n",
      "  - guidislink\n",
      "  - tags\n",
      "  - published\n",
      "  - published_parsed\n",
      "  - media_content\n",
      "\n",
      "============================================================\n",
      "FIRST ENTRY DETAILS:\n",
      "============================================================\n",
      "\n",
      "Title:\n",
      "Orange alert issued in north Tamil Nadu districts as Cyclone Montha advances\n",
      "\n",
      "Link:\n",
      "https://www.thehindu.com/news/national/tamil-nadu/cyclone-montha-orange-alert-issued-in-north-tamil-nadu-districts-as-weather-system-advances/article70207325.ece\n",
      "\n",
      "Description:\n",
      "In its Nowcast till 1 p.m. on Monday (October 27), the RMC has predicted moderate rains to continue over Chennai and its neighbouring districts, and Villupuram and Ranipet\n",
      "\n",
      "Published:\n",
      "Mon, 27 Oct 2025 12:23:45 +0530\n",
      "\n",
      "GUID:\n",
      "article-70207325\n",
      "\n",
      "Categories: ['Tamil Nadu']\n",
      "\n",
      "Media Content:\n",
      "  URL: https://th-i.thgim.com/public/incoming/z04cxf/article70207451.ece/alternates/LANDSCAPE_1200/2315_25_10_2025_16_55_13_2_CLOUDS2.JPG\n",
      "  Width: 1200, Height: 675\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Look at the first entry in detail\n",
    "if len(feed.entries) > 0:\n",
    "    print(\"🔍 INSPECTING FIRST ENTRY STRUCTURE\\n\")\n",
    "    first_entry = feed.entries[0]\n",
    "    \n",
    "    print(\"Available Keys:\")\n",
    "    for key in first_entry.keys():\n",
    "        print(f\"  - {key}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"FIRST ENTRY DETAILS:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    print(f\"\\nTitle:\\n{first_entry.get('title', 'N/A')}\")\n",
    "    print(f\"\\nLink:\\n{first_entry.get('link', 'N/A')}\")\n",
    "    print(f\"\\nDescription:\\n{first_entry.get('description', 'N/A')}\")\n",
    "    print(f\"\\nPublished:\\n{first_entry.get('published', 'N/A')}\")\n",
    "    print(f\"\\nGUID:\\n{first_entry.get('id', 'N/A')}\")\n",
    "    \n",
    "    # Check for category\n",
    "    if 'tags' in first_entry:\n",
    "        print(f\"\\nCategories: {[tag.get('term') for tag in first_entry.tags]}\")\n",
    "    \n",
    "    # Check for media content (images)\n",
    "    if 'media_content' in first_entry:\n",
    "        print(f\"\\nMedia Content:\")\n",
    "        for media in first_entry.media_content:\n",
    "            print(f\"  URL: {media.get('url', 'N/A')}\")\n",
    "            print(f\"  Width: {media.get('width', 'N/A')}, Height: {media.get('height', 'N/A')}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "else:\n",
    "    print(\"❌ No entries found in feed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1d405b1-263f-4fe3-9ea6-643b09f3c278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Extracting data from all entries...\n",
      "\n",
      "✅ Extracted 100 articles!\n"
     ]
    }
   ],
   "source": [
    "def extract_entry_data(entry):\n",
    "    \"\"\"\n",
    "    Extract relevant fields from a single RSS entry\n",
    "    \"\"\"\n",
    "    \n",
    "    # Basic fields\n",
    "    data = {\n",
    "        'title': entry.get('title', '').strip(),\n",
    "        'link': entry.get('link', '').strip(),\n",
    "        'description': entry.get('description', '').strip(),\n",
    "        'guid': entry.get('id', '').strip(),\n",
    "        'published': entry.get('published', ''),\n",
    "    }\n",
    "    \n",
    "    # Extract category\n",
    "    if 'tags' in entry and len(entry.tags) > 0:\n",
    "        data['category'] = entry.tags[0].get('term', '')\n",
    "    else:\n",
    "        data['category'] = ''\n",
    "    \n",
    "    # Extract image URL\n",
    "    if 'media_content' in entry and len(entry.media_content) > 0:\n",
    "        data['image_url'] = entry.media_content[0].get('url', '')\n",
    "        data['image_width'] = entry.media_content[0].get('width', '')\n",
    "        data['image_height'] = entry.media_content[0].get('height', '')\n",
    "    else:\n",
    "        data['image_url'] = ''\n",
    "        data['image_width'] = ''\n",
    "        data['image_height'] = ''\n",
    "    \n",
    "    # Parse published date\n",
    "    try:\n",
    "        if data['published']:\n",
    "            parsed_date = date_parser.parse(data['published'])\n",
    "            data['pub_date'] = parsed_date.strftime('%Y-%m-%d %H:%M:%S')\n",
    "            data['pub_date_readable'] = parsed_date.strftime('%d %b %Y, %I:%M %p')\n",
    "        else:\n",
    "            data['pub_date'] = ''\n",
    "            data['pub_date_readable'] = ''\n",
    "    except:\n",
    "        data['pub_date'] = data['published']\n",
    "        data['pub_date_readable'] = data['published']\n",
    "    \n",
    "    # Add flags\n",
    "    data['has_description'] = len(data['description']) > 0\n",
    "    data['has_image'] = len(data['image_url']) > 0\n",
    "    \n",
    "    # Add metadata\n",
    "    data['source'] = 'The Hindu - Tamil Nadu'\n",
    "    data['scraped_at'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    # Store raw entry as JSON (for debugging)\n",
    "    data['raw_json'] = json.dumps(dict(entry), default=str)\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "# Extract all entries\n",
    "print(\"🔄 Extracting data from all entries...\\n\")\n",
    "articles_data = []\n",
    "\n",
    "for entry in feed.entries:\n",
    "    article = extract_entry_data(entry)\n",
    "    articles_data.append(article)\n",
    "\n",
    "print(f\"✅ Extracted {len(articles_data)} articles!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59b5bbab-936f-4da6-be3f-ba1b307bd3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 DataFrame created successfully!\n",
      "Shape: (100, 15)\n",
      "Columns: ['title', 'description', 'link', 'pub_date', 'pub_date_readable', 'category', 'guid', 'image_url', 'has_description', 'has_image', 'source', 'scraped_at', 'image_width', 'image_height', 'raw_json']\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame\n",
    "df = pd.DataFrame(articles_data)\n",
    "\n",
    "# Reorder columns for better readability\n",
    "column_order = [\n",
    "    'title', \n",
    "    'description', \n",
    "    'link', \n",
    "    'pub_date',\n",
    "    'pub_date_readable',\n",
    "    'category', \n",
    "    'guid',\n",
    "    'image_url',\n",
    "    'has_description',\n",
    "    'has_image',\n",
    "    'source',\n",
    "    'scraped_at',\n",
    "    'image_width',\n",
    "    'image_height',\n",
    "    'raw_json'\n",
    "]\n",
    "\n",
    "df = df[column_order]\n",
    "\n",
    "print(\"📊 DataFrame created successfully!\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7764f622-fe2c-4fb1-94ff-c57e7358bdf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "📊 DATASET OVERVIEW\n",
      "============================================================\n",
      "\n",
      "📈 Total Articles: 100\n",
      "📅 Date Range: 23 Oct 2025, 08:01 PM to 27 Oct 2025, 12:23 PM\n",
      "\n",
      "============================================================\n",
      "📋 COLUMN INFO\n",
      "============================================================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 15 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   title              100 non-null    object\n",
      " 1   description        100 non-null    object\n",
      " 2   link               100 non-null    object\n",
      " 3   pub_date           100 non-null    object\n",
      " 4   pub_date_readable  100 non-null    object\n",
      " 5   category           100 non-null    object\n",
      " 6   guid               100 non-null    object\n",
      " 7   image_url          100 non-null    object\n",
      " 8   has_description    100 non-null    bool  \n",
      " 9   has_image          100 non-null    bool  \n",
      " 10  source             100 non-null    object\n",
      " 11  scraped_at         100 non-null    object\n",
      " 12  image_width        100 non-null    object\n",
      " 13  image_height       100 non-null    object\n",
      " 14  raw_json           100 non-null    object\n",
      "dtypes: bool(2), object(13)\n",
      "memory usage: 10.5+ KB\n",
      "\n",
      "============================================================\n",
      "🔍 DATA QUALITY CHECKS\n",
      "============================================================\n",
      "\n",
      "Missing Descriptions: 32 (32.0%)\n",
      "Missing Images: 23 (23.0%)\n",
      "Duplicate Links: 0\n",
      "\n",
      "============================================================\n",
      "📂 CATEGORY DISTRIBUTION\n",
      "============================================================\n",
      "category\n",
      "Tamil Nadu        83\n",
      "Chennai            5\n",
      "Coimbatore         4\n",
      "Madurai            2\n",
      "Andhra Pradesh     2\n",
      "India              1\n",
      "Health             1\n",
      "Tiruchirapalli     1\n",
      "Videos             1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"📊 DATASET OVERVIEW\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\n📈 Total Articles: {len(df)}\")\n",
    "print(f\"📅 Date Range: {df['pub_date_readable'].min()} to {df['pub_date_readable'].max()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"📋 COLUMN INFO\")\n",
    "print(\"=\" * 60)\n",
    "df.info()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"🔍 DATA QUALITY CHECKS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nMissing Descriptions: {(~df['has_description']).sum()} ({(~df['has_description']).sum() / len(df) * 100:.1f}%)\")\n",
    "print(f\"Missing Images: {(~df['has_image']).sum()} ({(~df['has_image']).sum() / len(df) * 100:.1f}%)\")\n",
    "print(f\"Duplicate Links: {df['link'].duplicated().sum()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"📂 CATEGORY DISTRIBUTION\")\n",
    "print(\"=\" * 60)\n",
    "print(df['category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e2423f2-4307-4594-9af6-1a1b1b5d9bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "📰 SAMPLE ARTICLES (First 5)\n",
      "============================================================\n",
      "                                                                                               title                                                                                                                                                                                                             description      pub_date_readable    category  has_description\n",
      "0                       Orange alert issued in north Tamil Nadu districts as Cyclone Montha advances                                             In its Nowcast till 1 p.m. on Monday (October 27), the RMC has predicted moderate rains to continue over Chennai and its neighbouring districts, and Villupuram and Ranipet  27 Oct 2025, 12:23 PM  Tamil Nadu             True\n",
      "1  Kalaignar International Convention Centre set for completion by February 2026: Minister E.V. Velu                                                                                                                                             The Public Works Department started the ₹525-crore project in May this year  27 Oct 2025, 11:59 AM     Chennai             True\n",
      "2                                           Eminent plastic surgeon K. Mathangi Ramakrishnan no more  She established the plastic surgery department and burns unit at Government Kilpauk Medical College, Chennai — one of the foremost government centres in India dedicated to comprehensive burn care and rehabilitation  27 Oct 2025, 11:09 AM  Tamil Nadu             True\n",
      "3                              What is the problem faced by paddy farmers of Tamil Nadu? | Explained                                                                                                                                           Why are there issues with procuring and storing paddy from the Cauvery delta?  27 Oct 2025, 08:30 AM  Tamil Nadu             True\n",
      "4                                                                  BM reviews works in Adyar estuary                                                 Besides the widening and desilting of Adyar estuary, the CM instructed officials to undertake the widening and desilting works in Cooum, Muttukadu and Ennore estuaries  27 Oct 2025, 07:35 AM  Tamil Nadu             True\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"📰 SAMPLE ARTICLES (First 5)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Display first 5 articles (excluding raw_json for readability)\n",
    "display_columns = ['title', 'description', 'pub_date_readable', 'category', 'has_description']\n",
    "print(df[display_columns].head().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e80b47dd-a02d-4acd-86b2-c377c16af310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "📏 DESCRIPTION LENGTH STATISTICS\n",
      "============================================================\n",
      "count    100.000000\n",
      "mean     121.360000\n",
      "std      108.944478\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%      128.500000\n",
      "75%      180.000000\n",
      "max      547.000000\n",
      "Name: description_length, dtype: float64\n",
      "\n",
      "📊 Length Distribution:\n",
      "Empty (0 chars): 32\n",
      "Short (1-50 chars): 0\n",
      "Medium (51-200 chars): 51\n",
      "Long (200+ chars): 17\n"
     ]
    }
   ],
   "source": [
    "# Analyze description lengths\n",
    "df['description_length'] = df['description'].str.len()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"📏 DESCRIPTION LENGTH STATISTICS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(df['description_length'].describe())\n",
    "\n",
    "print(\"\\n📊 Length Distribution:\")\n",
    "print(f\"Empty (0 chars): {(df['description_length'] == 0).sum()}\")\n",
    "print(f\"Short (1-50 chars): {((df['description_length'] > 0) & (df['description_length'] <= 50)).sum()}\")\n",
    "print(f\"Medium (51-200 chars): {((df['description_length'] > 50) & (df['description_length'] <= 200)).sum()}\")\n",
    "print(f\"Long (200+ chars): {(df['description_length'] > 200).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dddbd4a6-97a7-4e6f-b7b0-84f56182167d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "📊 RSS EXPLORATION SUMMARY REPORT\n",
      "============================================================\n",
      "\n",
      "✅ Feed Successfully Parsed\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
      "\n",
      "📰 Source: The Hindu - Tamil Nadu\n",
      "🔗 URL: https://www.thehindu.com/news/national/tamil-nadu/feeder/default.rss\n",
      "📅 Scraped At: 27 Oct 2025, 12:50 PM\n",
      "\n",
      "📊 STATISTICS\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
      "Total Articles: 100\n",
      "Date Range: 23 Oct 2025, 08:01 PM → 27 Oct 2025, 12:23 PM\n",
      "\n",
      "✅ Articles WITH Descriptions: 68 (68.0%)\n",
      "⚠️ Articles WITHOUT Descriptions: 32 (32.0%)\n",
      "\n",
      "🖼️ Articles WITH Images: 77 (77.0%)\n",
      "\n",
      "🏷️ CATEGORIES\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
      "category\n",
      "Tamil Nadu        83\n",
      "Chennai            5\n",
      "Coimbatore         4\n",
      "Madurai            2\n",
      "Andhra Pradesh     2\n",
      "India              1\n",
      "Health             1\n",
      "Tiruchirapalli     1\n",
      "Videos             1\n",
      "\n",
      "📝 DESCRIPTION STATS\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
      "Average Length: 121 characters\n",
      "Median Length: 128 characters\n",
      "Max Length: 547 characters\n",
      "\n",
      "💡 NEXT STEPS\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
      "1. For articles without descriptions, we need full-text scraping\n",
      "2. Run this notebook multiple times to collect historical data\n",
      "3. Export to CSV when satisfied\n",
      "4. Proceed to archive scraping for older data\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"📊 RSS EXPLORATION SUMMARY REPORT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\"\"\n",
    "✅ Feed Successfully Parsed\n",
    "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "📰 Source: The Hindu - Tamil Nadu\n",
    "🔗 URL: {RSS_URL}\n",
    "📅 Scraped At: {datetime.now().strftime('%d %b %Y, %I:%M %p')}\n",
    "\n",
    "📊 STATISTICS\n",
    "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "Total Articles: {len(df)}\n",
    "Date Range: {df['pub_date_readable'].min()} → {df['pub_date_readable'].max()}\n",
    "\n",
    "✅ Articles WITH Descriptions: {df['has_description'].sum()} ({df['has_description'].sum() / len(df) * 100:.1f}%)\n",
    "⚠️ Articles WITHOUT Descriptions: {(~df['has_description']).sum()} ({(~df['has_description']).sum() / len(df) * 100:.1f}%)\n",
    "\n",
    "🖼️ Articles WITH Images: {df['has_image'].sum()} ({df['has_image'].sum() / len(df) * 100:.1f}%)\n",
    "\n",
    "🏷️ CATEGORIES\n",
    "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "{df['category'].value_counts().to_string()}\n",
    "\n",
    "📝 DESCRIPTION STATS\n",
    "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "Average Length: {df['description_length'].mean():.0f} characters\n",
    "Median Length: {df['description_length'].median():.0f} characters\n",
    "Max Length: {df['description_length'].max():.0f} characters\n",
    "\n",
    "💡 NEXT STEPS\n",
    "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "1. For articles without descriptions, we need full-text scraping\n",
    "2. Run this notebook multiple times to collect historical data\n",
    "3. Export to CSV when satisfied\n",
    "4. Proceed to archive scraping for older data\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53908118-a895-4d77-9f19-1ef301cce14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data exported to: C:\\Users\\Yuvaraj\\Desktop\\Data-Science\\Mini-project\\tamil-news-drift-detection\\data\\raw\\hindu_rss_20251027_125409.csv\n",
      "📊 Exported 100 articles\n"
     ]
    }
   ],
   "source": [
    "# Uncomment when you're ready to export\n",
    "\n",
    "output_filename = rf\"C:\\Users\\Yuvaraj\\Desktop\\Data-Science\\Mini-project\\tamil-news-drift-detection\\data\\raw\\hindu_rss_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "\n",
    "\n",
    "# Export (excluding raw_json for smaller file size)\n",
    "export_columns = [col for col in df.columns if col != 'raw_json']\n",
    "df[export_columns].to_csv(output_filename, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"✅ Data exported to: {output_filename}\")\n",
    "print(f\"📊 Exported {len(df)} articles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a23c8f-0f12-4e24-a74b-3ea2bf5f3dea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13",
   "language": "python",
   "name": "python313"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
